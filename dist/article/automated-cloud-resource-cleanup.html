<!DOCTYPE html><!--87mPO66rg1PfPK5wLJkIl--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/07454f8ad8aaac57-s.p.fc65572f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/fa45df064ebe4be1.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/7f07730b362b6d01.js"/><script src="/_next/static/chunks/09e030ad03830b09.js" async=""></script><script src="/_next/static/chunks/6dff435a66c2f835.js" async=""></script><script src="/_next/static/chunks/ff05ccaef8b3e5bf.js" async=""></script><script src="/_next/static/chunks/turbopack-1b483ff455cc88c4.js" async=""></script><script src="/_next/static/chunks/fa74efd89e4b5edc.js" async=""></script><script src="/_next/static/chunks/d6bee75b35a28280.js" async=""></script><script src="/_next/static/chunks/8189c34e001333f7.js" async=""></script><script src="/_next/static/chunks/432e675556b35c78.js" async=""></script><meta name="next-size-adjust" content=""/><title>Automated Cloud Resource Cleanup: Stop Paying for What You&#x27;re Not Using | Cost Nimbus | Cost Nimbus</title><meta name="description" content="The average cloud account has 30-40% waste. Learn how to find and eliminate zombie resources automatically with Python, Bash, and open source tools."/><meta name="keywords" content="Cloud Cost Optimization, cloud costs, AWS optimization, FinOps, cloud savings, cost management"/><meta property="og:title" content="Cost Nimbus - Cloud Cost Intelligence"/><meta property="og:description" content="Real cloud cost optimization strategies built by engineers, for engineers. Save thousands monthly with battle-tested techniques."/><meta property="og:site_name" content="Cost Nimbus"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Cost Nimbus - Cloud Cost Intelligence"/><meta name="twitter:description" content="Real cloud cost optimization strategies built by engineers, for engineers. Save thousands monthly with battle-tested techniques."/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="space_grotesk_e6988195-module__RNs2Mq__variable nunito_faf8bdde-module__ZdPV6W__variable jetbrains_mono_7ea1d0f9-module__6GV5LG__variable antialiased" style="font-family:var(--font-nunito)"><div hidden=""><!--$--><!--/$--></div><nav style="position:fixed;top:0;left:0;right:0;background:var(--nav-bg);backdrop-filter:blur(20px);padding:1rem 2rem;z-index:100;box-shadow:0 2px 30px rgba(0, 0, 0, 0.3);animation:slideDown 0.7s ease-out"><div style="max-width:1100px;margin:0 auto;display:flex;justify-content:space-between;align-items:center"><a style="font-family:var(--font-space-grotesk);font-size:1.4rem;font-weight:700;color:var(--text-primary);text-decoration:none;display:flex;align-items:center;gap:0.5rem;transition:transform 0.3s ease" href="/"><span style="font-family:var(--font-jetbrains-mono);color:var(--accent-cyan);font-size:1.3rem">$</span>Cost Nimbus<span style="font-family:var(--font-nunito);font-size:0.7rem;color:var(--text-muted);margin-left:1rem;padding:0.4rem 1rem;background:rgba(0, 212, 255, 0.08);border-radius:20px;font-weight:600;border:1px solid rgba(0, 212, 255, 0.15)">Cloud Cost Intelligence</span></a><div style="display:flex;gap:1rem;align-items:center"><div style="display:flex;gap:1rem"><a style="font-family:var(--font-nunito);font-size:0.9rem;font-weight:600;color:var(--text-secondary);text-decoration:none;padding:0.6rem 1.3rem;border-radius:25px;transition:all 0.3s ease" href="/">Home</a><a style="font-family:var(--font-nunito);font-size:0.9rem;font-weight:600;color:var(--text-secondary);text-decoration:none;padding:0.6rem 1.3rem;border-radius:25px;transition:all 0.3s ease" href="/about">About</a><a style="font-family:var(--font-nunito);font-size:0.9rem;font-weight:600;color:var(--text-secondary);text-decoration:none;padding:0.6rem 1.3rem;border-radius:25px;transition:all 0.3s ease" href="/tools">Tools</a></div><button class="p-2 rounded-full transition-all duration-300 hover:scale-110 border border-transparent hover:border-opacity-30" style="background:rgba(255, 255, 255, 0.05);color:var(--text-secondary);border-color:var(--border-subtle)" aria-label="Switch to light mode"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun w-5 h-5" aria-hidden="true"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button></div></div></nav><header style="position:fixed;top:0;left:0;right:0;background:var(--nav-bg);backdrop-filter:blur(20px);padding:1rem 2rem;z-index:100;box-shadow:0 2px 30px rgba(0, 0, 0, 0.3);animation:slideDown 0.7s ease-out"><div style="max-width:1100px;margin:0 auto;display:flex;justify-content:space-between;align-items:center"><div><a style="font-family:var(--font-nunito);color:var(--text-secondary);text-decoration:none;font-size:0.9rem;display:inline-flex;align-items:center;gap:0.5rem;transition:all 0.3s ease" href="/">← Cost Nimbus</a></div><button class="p-2 rounded-full transition-all duration-300 hover:scale-110 border border-transparent hover:border-opacity-30" style="background:rgba(255, 255, 255, 0.05);color:var(--text-secondary);border-color:var(--border-subtle)" aria-label="Switch to light mode"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun w-5 h-5" aria-hidden="true"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button></div></header><article style="padding:10rem 2rem 6rem;max-width:900px;margin:0 auto;position:relative;z-index:1;animation:fadeInUp 0.9s ease-out 0.2s both"><header style="margin-bottom:4rem"><h1 style="font-family:var(--font-space-grotesk);font-size:clamp(2rem, 5vw, 3rem);font-weight:700;line-height:1.2;margin-bottom:1.5rem;color:var(--text-primary)">Automated Cloud Resource Cleanup: Stop Paying for What You&#x27;re Not Using</h1><p style="font-size:1.15rem;color:var(--text-secondary);margin-bottom:1.5rem;line-height:1.8">The average cloud account has 30-40% waste. Learn how to find and eliminate zombie resources automatically with Python, Bash, and open source tools.</p><div style="display:flex;align-items:center;gap:1rem;font-size:0.85rem;color:var(--text-muted);font-family:var(--font-jetbrains-mono)"><span style="padding:0.4rem 1rem;background:rgba(0, 212, 255, 0.1);color:var(--accent-cyan);border:1px solid rgba(0, 212, 255, 0.2);border-radius:20px">20 min<!-- --> read</span><span style="padding:0.4rem 1rem;background:rgba(168, 85, 247, 0.1);color:var(--accent-purple);border:1px solid rgba(168, 85, 247, 0.2);border-radius:20px">Cloud Cost Optimization</span></div></header><div style="line-height:1.8;color:var(--text-primary);font-size:1.05rem"><br/>The average cloud account has 30-40% waste. Here's how to find and eliminate it automatically.</p><p>In this guide, I'll show you how to identify zombie resources—unattached EBS volumes, old snapshots, idle instances, forgotten dev environments—and eliminate them with automated cleanup scripts. We'll cover manual audit techniques, Python automation, EventBridge scheduling, and open source tools like aws-nuke and Cloud Custodian.</p><p>Whether you're managing a single AWS account or dozens, these strategies will help you stop paying for resources you're not using.</p><p><h2>$2</h2></p><p>Cloud waste is silent, cumulative, and expensive. It doesn't happen overnight—it builds over months and years as teams spin up resources, forget them, and move on to the next project.</p><p><h3>The Numbers</h3></p><p>Let's start with the reality check:</p><p><li><strong>32% of cloud spend</strong> is wasted on unused resources (industry average)</li><br/><li><strong>$5.3 billion annually</strong> wasted on oversized resources alone</li><br/><li><strong>$22+ billion</strong> in global cloud waste per year</li><br/><li><strong>40% of instances</strong> run at less than 5% CPU utilization</li><br/><li><strong>Orphaned snapshots and volumes</strong> represent 1-3% of monthly spend without cleanup automation</li></p><p>These aren't theoretical numbers from white papers—they're from real audits of production environments.</p><p><h3>Real-World Examples</h3></p><p><strong>Case 1: 500 Unattached EBS Volumes</strong></p><p>A mid-sized startup had 500 EBS volumes with no attached instances:<br/><li>Volume types: 300 gp2, 200 io1</li><br/><li>Total size: 2.3 TB</li><br/><li>Monthly cost: $1,840</li></p><p>None of these volumes were attached to any instance. They were remnants from terminated instances that developers forgot to clean up.</p><p><strong>Case 2: 3,000 Old Snapshots</strong></p><p>An enterprise had accumulated 3,000 snapshots over 4 years:<br/><li>Average age: 180 days</li><br/><li>Total storage: 4.8 TB</li><br/><li>Monthly cost: $432</li><br/><li>Problem: Only 12 snapshots referenced by active AMIs</li></p><p>88% of snapshots had no purpose—they were just consuming storage and costing money.</p><p><strong>Case 3: 200 Unused Elastic IPs</strong></p><p>A development environment had 200 Elastic IPs not associated with any resource:<br/><li>Each EIP: $3.60/month</li><br/><li>Monthly cost: $720</li><br/><li>Problem: These addresses weren't even allocated to running instances</li></p><p><strong>Case 4: 87 Idle Instances</strong></p><p>A production environment had 87 EC2 instances running at <5% CPU for 30+ days:<br/><li>Instance types: Mix of m5.large, c5.xlarge, r5.2xlarge</li><br/><li>Monthly cost: $12,500</li><br/><li>Problem: These instances were ghost deployments from old projects</li></p><p><h3>Why Zombie Resources Accumulate</h3></p><p><strong>1. Terminated Instances ≠ Deleted Volumes</strong></p><p>When you terminate an EC2 instance, AWS gives you the option to delete attached volumes. If you don't explicitly select "Delete on Termination," the volume persists.</p><p><pre><code># Instance terminated<br/>aws ec2 terminate-instances --instance-ids i-0123456789abcdef0</p><p><h1>But the volume remains</h1><br/>aws ec2 describe-volumes --filters Name=attachment.instance-id,Values=i-0123456789abcdef0<br/><h1>Returns: The volume still exists, still costs money</h1><br/></code></pre></p><p><strong>2. Snapshot Sprawl</strong></p><p>Every backup creates a snapshot. Without retention policies:<br/><li>Automated backups create snapshots daily</li><br/><li>Manual snapshots before deployments</li><br/><li>Testing snapshots that are never deleted</li><br/><li>Old snapshots with no AMI reference</li></p><p><strong>3. Development Environments That Never Sleep</strong></p><p>Dev and staging environments often run 24/7 despite only being used during business hours:<br/><li>Usage pattern: 8 hours/day, 5 days/week</li><br/><li>Billing pattern: 24 hours/day, 7 days/week</li><br/><li>Waste: 67% of runtime cost</li></p><p><strong>4. Elastic IPs Without Purpose</strong></p><p>Elastic IPs cost $3.60/month even if not attached. Common causes:<br/><li>Released instances but kept the IP "just in case"</li><br/><li>Forgotten load balancers</li><br/><li>Test environments abandoned</li></p><p><strong>5. Oversized Instances</strong></p><p>Right-sizing issues:<br/><li>Initial deployment over-provisioning</li><br/><li>Workload changes over time</li><br/><li>Migration from on-prem (resources sized for physical hardware)</li><br/><li>"Better safe than sorry" mentality</li></p><p><h2>$2</h2></p><p>Before automating cleanup, you need to understand what you have. Start with a comprehensive manual audit.</p><p><h3>Step 1: Enable Cost Explorer</h3></p><p>Cost Explorer is your visibility tool—it's free and essential.</p><p><pre><code># Enable Cost Explorer (one-time setup)<br/>aws ce enable-ce<br/></code></pre></p><p>Once enabled, wait 24 hours for data to populate, then:</p><p><li>Go to AWS Console → Cost Management → Cost Explorer</li><br/><li>Create a "Monthly costs by service" view</li><br/><li>Create a "Daily costs" view</li><br/><li>Set up cost anomaly detection</li><br/><li>Create budgets for monitoring</li></p><p><h3>Step 2: Find Unattached EBS Volumes</h3></p><p><pre><code># Find all unattached EBS volumes in a region<br/>aws ec2 describe-volumes \<br/>  --filters Name=status,Values=available \<br/>  --query 'Volumes[?State==<code>available</code>].[VolumeId,Size,VolumeType,CreateTime]' \<br/>  --output table</p><p><h1>Calculate monthly cost of unattached volumes</h1><br/>aws ec2 describe-volumes \<br/>  --filters Name=status,Values=available \<br/>  --query 'Volumes[*].[VolumeId,Size,VolumeType]' \<br/>  --output json | jq -r '.[] | @csv' | while IFS=, read -r vid size type; do<br/>    # gp2 pricing: $0.10/GB/month in us-east-1<br/>    cost=$(echo "$size * 0.10" | bc)<br/>    echo "$vid,$size,$type,$\${cost}"<br/>  done<br/></code></pre></p><p><h3>Step 3: Find Old Snapshots</h3></p><p><pre><code># Find snapshots older than 90 days<br/>DATE=$(date -u -d '90 days ago' +%Y-%m-%dT%H:%M:%S)</p><p>aws ec2 describe-snapshots \<br/>  --owner-ids self \<br/>  --filters "Name=start-time,Values=,\${DATE}" \<br/>  --query 'Snapshots[*].[SnapshotId,VolumeSize,StartTime,Description]' \<br/>  --output table</p><p><h1>Find snapshots not referenced by any AMI</h1><br/>aws ec2 describe-snapshots \<br/>  --owner-ids self \<br/>  --query 'Snapshots[*].SnapshotId' \<br/>  --output text | while read snap_id; do<br/>    referenced=$(aws ec2 describe-images \<br/>      --filters Name=block-device-mapping.snapshot-id,Values=$snap_id \<br/>      --query 'Images | length(@)' \<br/>      --output text)<br/>    if [ "$referenced" == "0" ]; then<br/>      echo "$snap_id is not referenced by any AMI"<br/>    fi<br/>  done<br/></code></pre></p><p><h3>Step 4: Find Idle EC2 Instances</h3></p><p><pre><code># Get CPU utilization for all instances over 30 days<br/>aws cloudwatch get-metric-statistics \<br/>  --namespace AWS/EC2 \<br/>  --metric-name CPUUtilization \<br/>  --dimensions Name=InstanceId,Value=i-0123456789abcdef0 \<br/>  --start-time $(date -u -d '30 days ago' --iso-8601=seconds) \<br/>  --end-time $(date -u --iso-8601=seconds) \<br/>  --period 86400 \<br/>  --statistics Average \<br/>  --query 'Datapoints[0].Average'<br/></code></pre></p><p>Or use a Python script for all instances (see below).</p><p><h3>Step 5: Find Unused Elastic IPs</h3></p><p><pre><code># Find Elastic IPs not associated with any instance<br/>aws ec2 describe-addresses \<br/>  --query 'Addresses[?AssociationId==<code>null</code>].[PublicIp,AllocationId]' \<br/>  --output table</p><p><h1>Count and calculate cost</h1><br/>unused_eips=$(aws ec2 describe-addresses \<br/>  --query 'Addresses[?AssociationId==<code>null</code>] | length(@)' \<br/>  --output text)</p><p>monthly_cost=$(echo "$unused_eips * 3.60" | bc)<br/>echo "Unused EIPs: $unused_eips"<br/>echo "Monthly cost: $\${monthly_cost}"<br/></code></pre></p><p><h3>Step 6: Find Unused Lambda Versions</h3></p><p><pre><code># List all Lambda functions and their versions<br/>aws lambda list-functions \<br/>  --query 'Functions[*].[FunctionName,Version]' \<br/>  --output table</p><p><h1>Get all versions for a specific function</h1><br/>aws lambda list-versions-by-function \<br/>  --function-name my-function \<br/>  --query 'Versions[*].[Version,LastModified]' \<br/>  --output table<br/></code></pre></p><p><h2>$2</h2></p><p>Now let's build automation that finds and eliminates zombie resources. These scripts are production-ready with safety checks and dry-run modes.</p><p><h3>Script 1: Find and Delete Unattached EBS Volumes</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>EBS Volume Cleanup Script<br/>Finds and deletes unattached EBS volumes with safety checks.<br/>"""</p><p>import boto3<br/>from datetime import datetime, timedelta<br/>import sys</p><p>def get_unattached_volumes(dry_run=True):<br/>    """Get all volumes not attached to any instance."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    # Filter for available (unattached) volumes<br/>    response = ec2.describe_volumes(<br/>        Filters=[<br/>            {'Name': 'status', 'Values': ['available']}<br/>        ]<br/>    )<br/>    <br/>    volumes = response['Volumes']<br/>    print(""<br/>    <br/>    # Calculate total cost<br/>    total_size = sum(v['Size'] for v in volumes)<br/>    # gp2 pricing in us-east-1: $0.10/GB/month<br/>    monthly_cost = total_size * 0.10<br/>    <br/>    print("Total size: {} GB".format(total_size))<br/>    print("Monthly cost: ${:.2f}".format(monthly_cost))<br/>    <br/>    return volumes</p><p>def check_tags(volume):<br/>    """Check if volume has exemption tags."""<br/>    tags = volume.get('Tags', [])<br/>    tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>    <br/>    # Exempt if any of these tags exist<br/>    exempt_tags = ['do-not-delete', 'preserve', 'keep', 'exempt']<br/>    <br/>    for exempt_tag in exempt_tags:<br/>        if exempt_tag in tag_dict:<br/>            print(""<br/>            return True<br/>    <br/>    return False</p><p>def delete_volume(volume_id, dry_run=True):<br/>    """Delete a volume with safety checks."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    try:<br/>        if dry_run:<br/>            print(""<br/>        else:<br/>            ec2.delete_volume(VolumeId=volume_id)<br/>            print(""<br/>        return True<br/>    except Exception as e:<br/>        print(""<br/>        return False</p><p>def main():<br/>    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv<br/>    force = '--force' in sys.argv or '-f' in sys.argv<br/>    <br/>    if dry_run:<br/>        print("=" * 60)<br/>        print("DRY RUN MODE - No changes will be made")<br/>        print("=" * 60)<br/>    else:<br/>        print("=" * 60)<br/>        print("PRODUCTION MODE - Volumes WILL be deleted!")<br/>        print("=" * 60)<br/>    <br/>    if not dry_run and not force:<br/>        confirm = input("\nThis will delete unattached volumes. Continue? (yes/no): ")<br/>        if confirm.lower() != 'yes':<br/>            print("Aborted.")<br/>            sys.exit(0)<br/>    <br/>    volumes = get_unattached_volumes(dry_run)<br/>    <br/>    if not volumes:<br/>        print("No unattached volumes found.")<br/>        return<br/>    <br/>    deleted_count = 0<br/>    exempt_count = 0<br/>    total_size_deleted = 0<br/>    <br/>    for volume in volumes:<br/>        volume_id = volume['VolumeId']<br/>        size = volume['Size']<br/>        create_time = volume['CreateTime']<br/>        age_days = (datetime.now(create_time.tzinfo) - create_time).days<br/>        <br/>        print(""<br/>        <br/>        # Check exemption tags<br/>        if check_tags(volume):<br/>            exempt_count += 1<br/>            continue<br/>        <br/>        # Additional safety: volumes created in last 7 days<br/>        if age_days < 7:<br/>            print(""<br/>            exempt_count += 1<br/>            continue<br/>        <br/>        # Delete the volume<br/>        if delete_volume(volume_id, dry_run):<br/>            deleted_count += 1<br/>            total_size_deleted += size<br/>    <br/>    print("\n" + "=" * 60)<br/>    print(""<br/>    print(""<br/>    print(""<br/>    print(""</p><p>if __name__ == '__main__':<br/>    main()<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Dry run (safe, see what would be deleted)<br/>python3 cleanup_ebs.py --dry-run</p><p><h1>Production run (with confirmation)</h1><br/>python3 cleanup_ebs.py</p><p><h1>Production run (force, no confirmation)</h1><br/>python3 cleanup_ebs.py --force<br/></code></pre></p><p><h3>Script 2: Clean Old Snapshots</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>Snapshot Cleanup Script<br/>Deletes old snapshots not referenced by any AMI.<br/>"""</p><p>import boto3<br/>from datetime import datetime, timedelta, timezone<br/>import sys</p><p>def get_old_snapshots(days=90, dry_run=True):<br/>    """Get snapshots older than specified days."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)<br/>    <br/>    response = ec2.describe_snapshots(<br/>        OwnerIds=['self'],<br/>        Filters=[<br/>            {'Name': 'start-time', 'Values': [f',\{cutoff_date.isoformat()}']}<br/>        ]<br/>    )<br/>    <br/>    snapshots = response['Snapshots']<br/>    print(""<br/>    <br/>    return snapshots</p><p>def is_snapshot_referenced(snapshot_id):<br/>    """Check if snapshot is referenced by any AMI."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    response = ec2.describe_images(<br/>        Filters=[<br/>            {'Name': 'block-device-mapping.snapshot-id', 'Values': [snapshot_id]}<br/>        ]<br/>    )<br/>    <br/>    return len(response['Images']) > 0</p><p>def delete_snapshot(snapshot_id, dry_run=True):<br/>    """Delete a snapshot."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    try:<br/>        if dry_run:<br/>            print(""<br/>        else:<br/>            ec2.delete_snapshot(SnapshotId=snapshot_id)<br/>            print(""<br/>        return True<br/>    except Exception as e:<br/>        print(""<br/>        return False</p><p>def main():<br/>    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv<br/>    force = '--force' in sys.argv or '-f' in sys.argv<br/>    days = int(sys.argv[sys.argv.index('--days') + 1]) if '--days' in sys.argv else 90<br/>    <br/>    if dry_run:<br/>        print("=" * 60)<br/>        print(""<br/>        print(""<br/>        print("=" * 60)<br/>    else:<br/>        print("=" * 60)<br/>        print(""<br/>        print(""<br/>        print("=" * 60)<br/>    <br/>    if not dry_run and not force:<br/>        confirm = input("\nThis will delete old unreferenced snapshots. Continue? (yes/no): ")<br/>        if confirm.lower() != 'yes':<br/>            print("Aborted.")<br/>            sys.exit(0)<br/>    <br/>    snapshots = get_old_snapshots(days, dry_run)<br/>    <br/>    if not snapshots:<br/>        print("No old snapshots found.")<br/>        return<br/>    <br/>    deleted_count = 0<br/>    exempt_count = 0<br/>    total_size_deleted = 0<br/>    <br/>    for snapshot in snapshots:<br/>        snapshot_id = snapshot['SnapshotId']<br/>        size = snapshot['VolumeSize']<br/>        start_time = snapshot['StartTime']<br/>        description = snapshot.get('Description', '')<br/>        <br/>        age_days = (datetime.now(timezone.utc) - start_time).days<br/>        <br/>        print(""<br/>        if description:<br/>            print(""<br/>        <br/>        # Check if referenced by AMI<br/>        if is_snapshot_referenced(snapshot_id):<br/>            print(""<br/>            exempt_count += 1<br/>            continue<br/>        <br/>        # Check exemption tags<br/>        tags = snapshot.get('Tags', [])<br/>        tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>        <br/>        exempt_tags = ['do-not-delete', 'preserve', 'keep', 'backup']<br/>        for exempt_tag in exempt_tags:<br/>            if exempt_tag in tag_dict:<br/>                print(""<br/>                exempt_count += 1<br/>                continue<br/>        <br/>        # Delete the snapshot<br/>        if delete_snapshot(snapshot_id, dry_run):<br/>            deleted_count += 1<br/>            total_size_deleted += size<br/>    <br/>    print("\n" + "=" * 60)<br/>    print(""<br/>    print(""<br/>    print(""<br/>    # Snapshot pricing in us-east-1: $0.05/GB/month<br/>    print(""</p><p>if __name__ == '__main__':<br/>    main()<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Dry run for snapshots older than 90 days<br/>python3 cleanup_snapshots.py --dry-run --days 90</p><p><h1>Delete snapshots older than 180 days</h1><br/>python3 cleanup_snapshots.py --days 180</p><p><h1>Force delete (no confirmation)</h1><br/>python3 cleanup_snapshots.py --days 90 --force<br/></code></pre></p><p><h3>Script 3: Stop Idle EC2 Instances</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>Idle EC2 Instance Cleanup<br/>Stops instances with CPU < 5% for 7+ days.<br/>"""</p><p>import boto3<br/>from datetime import datetime, timedelta, timezone<br/>import sys</p><p>def get_instance_cpu(instance_id, days=7):<br/>    """Get average CPU utilization for an instance."""<br/>    cloudwatch = boto3.client('cloudwatch')<br/>    <br/>    end_time = datetime.now(timezone.utc)<br/>    start_time = end_time - timedelta(days=days)<br/>    <br/>    response = cloudwatch.get_metric_statistics(<br/>        Namespace='AWS/EC2',<br/>        MetricName='CPUUtilization',<br/>        Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],<br/>        StartTime=start_time,<br/>        EndTime=end_time,<br/>        Period=86400,  # Daily<br/>        Statistics=['Average']<br/>    )<br/>    <br/>    datapoints = response['Datapoints']<br/>    if not datapoints:<br/>        return None<br/>    <br/>    avg_cpu = sum(dp['Average'] for dp in datapoints) / len(datapoints)<br/>    return avg_cpu</p><p>def check_instance_tags(instance):<br/>    """Check if instance has exemption tags."""<br/>    tags = instance.get('Tags', [])<br/>    tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>    <br/>    exempt_tags = ['do-not-stop', 'always-on', 'production', 'critical']<br/>    <br/>    for exempt_tag in exempt_tags:<br/>        if exempt_tag.lower() in [k.lower() for k in tag_dict.keys()]:<br/>            print(""<br/>            return True<br/>    <br/>    return False</p><p>def stop_instance(instance_id, dry_run=True):<br/>    """Stop an EC2 instance."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    try:<br/>        if dry_run:<br/>            print(""<br/>        else:<br/>            ec2.stop_instances(InstanceIds=[instance_id])<br/>            print(""<br/>        return True<br/>    except Exception as e:<br/>        print(""<br/>        return False</p><p>def main():<br/>    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv<br/>    force = '--force' in sys.argv or '-f' in sys.argv<br/>    cpu_threshold = float(sys.argv[sys.argv.index('--cpu') + 1]) if '--cpu' in sys.argv else 5.0<br/>    days = int(sys.argv[sys.argv.index('--days') + 1]) if '--days' in sys.argv else 7<br/>    <br/>    ec2 = boto3.client('ec2')<br/>    <br/>    # Get all running instances<br/>    response = ec2.describe_instances(<br/>        Filters=[<br/>            {'Name': 'instance-state-name', 'Values': ['running']}<br/>        ]<br/>    )<br/>    <br/>    instances = []<br/>    for reservation in response['Reservations']:<br/>        instances.extend(reservation['Instances'])<br/>    <br/>    print(""<br/>    <br/>    if dry_run:<br/>        print("=" * 60)<br/>        print("DRY RUN MODE - No instances will be stopped")<br/>        print(""<br/>        print("=" * 60)<br/>    else:<br/>        print("=" * 60)<br/>        print("PRODUCTION MODE - Instances WILL be stopped!")<br/>        print(""<br/>        print("=" * 60)<br/>    <br/>    if not dry_run and not force:<br/>        confirm = input("\nThis will stop idle instances. Continue? (yes/no): ")<br/>        if confirm.lower() != 'yes':<br/>            print("Aborted.")<br/>            sys.exit(0)<br/>    <br/>    stopped_count = 0<br/>    exempt_count = 0<br/>    <br/>    for instance in instances:<br/>        instance_id = instance['InstanceId']<br/>        instance_type = instance['InstanceType']<br/>        launch_time = instance['LaunchTime']<br/>        <br/>        # Skip instances launched in last 30 days<br/>        age_days = (datetime.now(timezone.utc) - launch_time).days<br/>        if age_days < 30:<br/>            continue<br/>        <br/>        # Get CPU utilization<br/>        avg_cpu = get_instance_cpu(instance_id, days)<br/>        <br/>        if avg_cpu is None:<br/>            print(""<br/>            print(""<br/>            continue<br/>        <br/>        print(""<br/>        print(""<br/>        <br/>        if avg_cpu >= cpu_threshold:<br/>            print(""<br/>            continue<br/>        <br/>        # Check exemption tags<br/>        if check_instance_tags(instance):<br/>            exempt_count += 1<br/>            continue<br/>        <br/>        # Stop the instance<br/>        if stop_instance(instance_id, dry_run):<br/>            stopped_count += 1<br/>    <br/>    print("\n" + "=" * 60)<br/>    print(""<br/>    print(""<br/>    print(""</p><p>if __name__ == '__main__':<br/>    main()<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Dry run: find instances with CPU < 5% for 7 days<br/>python3 cleanup_instances.py --dry-run --cpu 5.0 --days 7</p><p><h1>Stop instances with CPU < 3% for 14 days</h1><br/>python3 cleanup_instances.py --cpu 3.0 --days 14</p><p><h1>Force stop (no confirmation)</h1><br/>python3 cleanup_instances.py --cpu 5.0 --days 7 --force<br/></code></pre></p><p><h3>Script 4: Delete Unused Elastic IPs</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>Elastic IP Cleanup Script<br/>Releases Elastic IPs not associated with any resource.<br/>"""</p><p>import boto3<br/>import sys</p><p>def get_unused_eips(dry_run=True):<br/>    """Get Elastic IPs not associated with any instance."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    response = ec2.describe_addresses()<br/>    <br/>    unused_eips = [<br/>        addr for addr in response['Addresses']<br/>        if addr.get('AssociationId') is None<br/>    ]<br/>    <br/>    print(""<br/>    print(""<br/>    <br/>    return unused_eips</p><p>def check_tags(address):<br/>    """Check if address has exemption tags."""<br/>    tags = address.get('Tags', [])<br/>    tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>    <br/>    exempt_tags = ['do-not-delete', 'preserve', 'keep']<br/>    <br/>    for exempt_tag in exempt_tags:<br/>        if exempt_tag in tag_dict:<br/>            print(""<br/>            return True<br/>    <br/>    return False</p><p>def release_eip(allocation_id, dry_run=True):<br/>    """Release an Elastic IP."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    try:<br/>        if dry_run:<br/>            print(""<br/>        else:<br/>            ec2.release_address(AllocationId=allocation_id)<br/>            print(""<br/>        return True<br/>    except Exception as e:<br/>        print(""<br/>        return False</p><p>def main():<br/>    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv<br/>    force = '--force' in sys.argv or '-f' in sys.argv<br/>    <br/>    if dry_run:<br/>        print("=" * 60)<br/>        print("DRY RUN MODE - No EIPs will be released")<br/>        print("=" * 60)<br/>    else:<br/>        print("=" * 60)<br/>        print("PRODUCTION MODE - EIPs WILL be released!")<br/>        print("=" * 60)<br/>    <br/>    if not dry_run and not force:<br/>        confirm = input("\nThis will release unused Elastic IPs. Continue? (yes/no): ")<br/>        if confirm.lower() != 'yes':<br/>            print("Aborted.")<br/>            sys.exit(0)<br/>    <br/>    eips = get_unused_eips(dry_run)<br/>    <br/>    if not eips:<br/>        print("No unused Elastic IPs found.")<br/>        return<br/>    <br/>    released_count = 0<br/>    exempt_count = 0<br/>    <br/>    for addr in eips:<br/>        public_ip = addr['PublicIp']<br/>        allocation_id = addr['AllocationId']<br/>        <br/>        print(""<br/>        <br/>        # Check exemption tags<br/>        if check_tags(addr):<br/>            exempt_count += 1<br/>            continue<br/>        <br/>        # Release the address<br/>        if release_eip(allocation_id, dry_run):<br/>            released_count += 1<br/>    <br/>    print("\n" + "=" * 60)<br/>    print(""<br/>    print(""<br/>    print(""<br/>    print(""</p><p>if __name__ == '__main__':<br/>    main()<br/></code></pre></p><p><h3>Script 5: Clean Old Lambda Versions</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>Lambda Version Cleanup Script<br/>Deletes old versions of Lambda functions.<br/>"""</p><p>import boto3<br/>from datetime import datetime, timedelta, timezone<br/>import sys</p><p>def get_lambda_versions(function_name, keep_versions=5, dry_run=True):<br/>    """Get old versions of a Lambda function."""<br/>    lambda_client = boto3.client('lambda')<br/>    <br/>    response = lambda_client.list_versions_by_function(<br/>        FunctionName=function_name<br/>    )<br/>    <br/>    versions = response['Versions']<br/>    <br/>    # Sort by last modified (newest first)<br/>    versions.sort(key=lambda v: v.get('LastModified', datetime.now(timezone.utc)), reverse=True)<br/>    <br/>    # Keep the latest versions<br/>    versions_to_delete = versions[keep_versions:]<br/>    <br/>    if versions_to_delete:<br/>        print(""<br/>    <br/>    return versions_to_delete</p><p>def delete_lambda_version(function_name, version, dry_run=True):<br/>    """Delete a specific Lambda version."""<br/>    lambda_client = boto3.client('lambda')<br/>    <br/>    try:<br/>        if dry_run:<br/>            print(""<br/>        else:<br/>            lambda_client.delete_function(<br/>                FunctionName=function_name,<br/>                Qualifier=version<br/>            )<br/>            print(""<br/>        return True<br/>    except Exception as e:<br/>        print(""<br/>        return False</p><p>def main():<br/>    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv<br/>    force = '--force' in sys.argv or '-f' in sys.argv<br/>    keep_versions = int(sys.argv[sys.argv.index('--keep') + 1]) if '--keep' in sys.argv else 5<br/>    <br/>    lambda_client = boto3.client('lambda')<br/>    <br/>    # Get all Lambda functions<br/>    response = lambda_client.list_functions()<br/>    <br/>    functions = [func['FunctionName'] for func in response['Functions']]<br/>    print(""<br/>    <br/>    if dry_run:<br/>        print("=" * 60)<br/>        print("DRY RUN MODE - No versions will be deleted")<br/>        print(""<br/>        print("=" * 60)<br/>    else:<br/>        print("=" * 60)<br/>        print("PRODUCTION MODE - Versions WILL be deleted!")<br/>        print(""<br/>        print("=" * 60)<br/>    <br/>    if not dry_run and not force:<br/>        confirm = input("\nThis will delete old Lambda versions. Continue? (yes/no): ")<br/>        if confirm.lower() != 'yes':<br/>            print("Aborted.")<br/>            sys.exit(0)<br/>    <br/>    deleted_count = 0<br/>    <br/>    for function_name in functions:<br/>        old_versions = get_lambda_versions(function_name, keep_versions, dry_run)<br/>        <br/>        for version in old_versions:<br/>            version_num = version['Version']<br/>            <br/>            # Never delete $LATEST<br/>            if version_num == '$LATEST':<br/>                continue<br/>            <br/>            if delete_lambda_version(function_name, version_num, dry_run):<br/>                deleted_count += 1<br/>    <br/>    print("\n" + "=" * 60)<br/>    print(""<br/>    print(""</p><p>if __name__ == '__main__':<br/>    main()<br/></code></pre></p><p><h2>$2</h2></p><p>Manual scripts are great, but automated is better. Let's set up scheduled cleanup using EventBridge and Lambda.</p><p><h3>Step 1: Create IAM Role for Lambda</h3></p><p><pre><code># Create IAM policy for cleanup<br/>cat > cleanup-policy.json <<'EOF'<br/>{<br/>  "Version": "2012-10-17",<br/>  "Statement": [<br/>    {<br/>      "Effect": "Allow",<br/>      "Action": [<br/>        "ec2:DescribeVolumes",<br/>        "ec2:DeleteVolume",<br/>        "ec2:DescribeSnapshots",<br/>        "ec2:DeleteSnapshot",<br/>        "ec2:DescribeInstances",<br/>        "ec2:StopInstances",<br/>        "ec2:DescribeAddresses",<br/>        "ec2:ReleaseAddress",<br/>        "cloudwatch:GetMetricStatistics"<br/>      ],<br/>      "Resource": "*"<br/>    }<br/>  ]<br/>}<br/>EOF</p><p><h1>Create policy</h1><br/>aws iam create-policy \<br/>  --policy-name LambdaCleanupPolicy \<br/>  --policy-document file://cleanup-policy.json</p><p><h1>Get policy ARN</h1><br/>POLICY_ARN=$(aws iam list-policies \<br/>  --query "Policies[?PolicyName=='LambdaCleanupPolicy'].Arn" \<br/>  --output text)</p><p><h1>Create IAM role</h1><br/>cat > trust-policy.json <<'EOF'<br/>{<br/>  "Version": "2012-10-17",<br/>  "Statement": [<br/>    {<br/>      "Effect": "Allow",<br/>      "Principal": {<br/>        "Service": "lambda.amazonaws.com"<br/>      },<br/>      "Action": "sts:AssumeRole"<br/>    }<br/>  ]<br/>}<br/>EOF</p><p>aws iam create-role \<br/>  --role-name LambdaCleanupRole \<br/>  --assume-role-policy-document file://trust-policy.json</p><p><h1>Attach policy to role</h1><br/>aws iam attach-role-policy \<br/>  --role-name LambdaCleanupRole \<br/>  --policy-arn $POLICY_ARN<br/></code></pre></p><p><h3>Step 2: Create Lambda Function</h3></p><p><pre><code># lambda_handler.py<br/>import json<br/>import boto3<br/>from datetime import datetime, timedelta, timezone</p><p>def lambda_handler(event, context):<br/>    """Lambda handler for scheduled cleanup."""<br/>    print(""<br/>    <br/>    # Get configuration from event<br/>    config = event.get('config', {})<br/>    <br/>    results = {<br/>        'timestamp': datetime.now(timezone.utc).isoformat(),<br/>        'cleanup_tasks': []<br/>    }<br/>    <br/>    # EBS Volume Cleanup<br/>    if config.get('cleanup_ebs', False):<br/>        result = cleanup_ebs(dry_run=config.get('dry_run', False))<br/>        results['cleanup_tasks'].append({<br/>            'task': 'cleanup_ebs',<br/>            'result': result<br/>        })<br/>    <br/>    # Snapshot Cleanup<br/>    if config.get('cleanup_snapshots', False):<br/>        result = cleanup_snapshots(<br/>            days=config.get('snapshot_days', 90),<br/>            dry_run=config.get('dry_run', False)<br/>        )<br/>        results['cleanup_tasks'].append({<br/>            'task': 'cleanup_snapshots',<br/>            'result': result<br/>        })<br/>    <br/>    # EC2 Instance Cleanup<br/>    if config.get('cleanup_instances', False):<br/>        result = cleanup_instances(<br/>            cpu_threshold=config.get('cpu_threshold', 5.0),<br/>            days=config.get('instance_days', 7),<br/>            dry_run=config.get('dry_run', False)<br/>        )<br/>        results['cleanup_tasks'].append({<br/>            'task': 'cleanup_instances',<br/>            'result': result<br/>        })<br/>    <br/>    print(""<br/>    <br/>    return {<br/>        'statusCode': 200,<br/>        'body': json.dumps(results)<br/>    }</p><p>def cleanup_ebs(dry_run=True):<br/>    """Cleanup unattached EBS volumes."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    response = ec2.describe_volumes(<br/>        Filters=[{'Name': 'status', 'Values': ['available']}]<br/>    )<br/>    <br/>    volumes = response['Volumes']<br/>    deleted = 0<br/>    exempted = 0<br/>    size_deleted = 0<br/>    <br/>    for volume in volumes:<br/>        volume_id = volume['VolumeId']<br/>        tags = volume.get('Tags', [])<br/>        tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>        <br/>        # Check exemption tags<br/>        if any(tag in tag_dict for tag in ['do-not-delete', 'preserve', 'keep']):<br/>            exempted += 1<br/>            continue<br/>        <br/>        try:<br/>            if not dry_run:<br/>                ec2.delete_volume(VolumeId=volume_id)<br/>            deleted += 1<br/>            size_deleted += volume['Size']<br/>        except Exception as e:<br/>            print(""<br/>    <br/>    return {<br/>        'deleted': deleted,<br/>        'exempted': exempted,<br/>        'size_gb': size_deleted<br/>    }</p><p>def cleanup_snapshots(days=90, dry_run=True):<br/>    """Cleanup old unreferenced snapshots."""<br/>    ec2 = boto3.client('ec2')<br/>    <br/>    cutoff = datetime.now(timezone.utc) - timedelta(days=days)<br/>    <br/>    response = ec2.describe_snapshots(<br/>        OwnerIds=['self'],<br/>        Filters=[<br/>            {'Name': 'start-time', 'Values': [f',\{cutoff.isoformat()}']}<br/>        ]<br/>    )<br/>    <br/>    snapshots = response['Snapshots']<br/>    deleted = 0<br/>    exempted = 0<br/>    size_deleted = 0<br/>    <br/>    for snapshot in snapshots:<br/>        snapshot_id = snapshot['SnapshotId']<br/>        <br/>        # Check if referenced by AMI<br/>        ami_response = ec2.describe_images(<br/>            Filters=[<br/>                {'Name': 'block-device-mapping.snapshot-id', 'Values': [snapshot_id]}<br/>            ]<br/>        )<br/>        <br/>        if len(ami_response['Images']) > 0:<br/>            exempted += 1<br/>            continue<br/>        <br/>        try:<br/>            if not dry_run:<br/>                ec2.delete_snapshot(SnapshotId=snapshot_id)<br/>            deleted += 1<br/>            size_deleted += snapshot['VolumeSize']<br/>        except Exception as e:<br/>            print(""<br/>    <br/>    return {<br/>        'deleted': deleted,<br/>        'exempted': exempted,<br/>        'size_gb': size_deleted<br/>    }</p><p>def cleanup_instances(cpu_threshold=5.0, days=7, dry_run=True):<br/>    """Cleanup idle EC2 instances."""<br/>    ec2 = boto3.client('ec2')<br/>    cloudwatch = boto3.client('cloudwatch')<br/>    <br/>    response = ec2.describe_instances(<br/>        Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]<br/>    )<br/>    <br/>    instances = []<br/>    for reservation in response['Reservations']:<br/>        instances.extend(reservation['Instances'])<br/>    <br/>    stopped = 0<br/>    exempted = 0<br/>    <br/>    for instance in instances:<br/>        instance_id = instance['InstanceId']<br/>        <br/>        # Check exemption tags<br/>        tags = instance.get('Tags', [])<br/>        tag_dict = {tag['Key']: tag['Value'] for tag in tags}<br/>        <br/>        if any(tag.lower() in [k.lower() for k in tag_dict.keys()] <br/>               for tag in ['do-not-stop', 'always-on', 'production']):<br/>            exempted += 1<br/>            continue<br/>        <br/>        # Get CPU<br/>        end_time = datetime.now(timezone.utc)<br/>        start_time = end_time - timedelta(days=days)<br/>        <br/>        metrics_response = cloudwatch.get_metric_statistics(<br/>            Namespace='AWS/EC2',<br/>            MetricName='CPUUtilization',<br/>            Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],<br/>            StartTime=start_time,<br/>            EndTime=end_time,<br/>            Period=86400,<br/>            Statistics=['Average']<br/>        )<br/>        <br/>        datapoints = metrics_response['Datapoints']<br/>        if not datapoints:<br/>            continue<br/>        <br/>        avg_cpu = sum(dp['Average'] for dp in datapoints) / len(datapoints)<br/>        <br/>        if avg_cpu < cpu_threshold:<br/>            try:<br/>                if not dry_run:<br/>                    ec2.stop_instances(InstanceIds=[instance_id])<br/>                stopped += 1<br/>            except Exception as e:<br/>                print(""<br/>    <br/>    return {<br/>        'stopped': stopped,<br/>        'exempted': exempted<br/>    }<br/></code></pre></p><p><h3>Step 3: Package and Deploy Lambda</h3></p><p><pre><code># Create deployment package<br/>zip lambda_cleanup.zip lambda_handler.py</p><p><h1>Create Lambda function</h1><br/>aws lambda create-function \<br/>  --function-name cloud-cleanup \<br/>  --runtime python3.11 \<br/>  --role arn:aws:iam::123456789012:role/LambdaCleanupRole \<br/>  --handler lambda_handler.lambda_handler \<br/>  --zip-file fileb://lambda_cleanup.zip \<br/>  --timeout 300 \<br/>  --memory-size 512</p><p><h1>Update function (for later updates)</h1><br/>aws lambda update-function-code \<br/>  --function-name cloud-cleanup \<br/>  --zip-file fileb://lambda_cleanup.zip<br/></code></pre></p><p><h3>Step 4: Create EventBridge Rule</h3></p><p><pre><code># Create EventBridge rule (weekly cleanup, Monday 2 AM UTC)<br/>aws events put-rule \<br/>  --name weekly-cloud-cleanup \<br/>  --schedule-expression 'cron(0 2 ? * MON *)' \<br/>  --description 'Weekly cloud resource cleanup'</p><p><h1>Add Lambda as target</h1><br/>aws lambda add-permission \<br/>  --function-name cloud-cleanup \<br/>  --statement-id events-invoke \<br/>  --action lambda:InvokeFunction \<br/>  --principal events.amazonaws.com \<br/>  --source-arn arn:aws:events:us-east-1:123456789012:rule/weekly-cloud-cleanup</p><p>aws events put-targets \<br/>  --rule weekly-cloud-cleanup \<br/>  --targets '{<br/>    "Id": "1",<br/>    "Arn": "arn:aws:lambda:us-east-1:123456789012:function:cloud-cleanup",<br/>    "Input": "{<br/>      \"config\": {<br/>        \"cleanup_ebs\": true,<br/>        \"cleanup_snapshots\": true,<br/>        \"cleanup_instances\": true,<br/>        \"dry_run\": false,<br/>        \"snapshot_days\": 90,<br/>        \"cpu_threshold\": 5.0,<br/>        \"instance_days\": 7<br/>      }<br/>    }"<br/>  }'<br/></code></pre></p><p><h3>Step 5: Test Lambda Invocation</h3></p><p><pre><code># Test invocation (dry run)<br/>aws lambda invoke \<br/>  --function-name cloud-cleanup \<br/>  --payload '{<br/>    "config": {<br/>      "cleanup_ebs": true,<br/>      "cleanup_snapshots": true,<br/>      "cleanup_instances": true,<br/>      "dry_run": true<br/>    }<br/>  }' \<br/>  response.json</p><p><h1>View logs</h1><br/>aws logs tail /aws/lambda/cloud-cleanup --follow<br/></code></pre></p><p><h2>$2</h2></p><p>Custom scripts are powerful, but mature open source tools offer more features and community support.</p><p><h3>aws-nuke</h3></p><p><strong>aws-nuke</strong> is a tool for cleaning up AWS accounts by nuking (deleting) all resources. It's designed for cleaning up test accounts or entire environments.</p><p><strong>Installation:</strong></p><p><pre><code># Download latest release<br/>curl -L https://github.com/rebuy-de/aws-nuke/releases/download/v3.30.0/aws-nuke-v3.30.0-linux-amd64.tar.gz | tar xz</p><p><h1>Move to PATH</h1><br/>sudo mv aws-nuke-v3.30.0-linux-amd64 /usr/local/bin/aws-nuke<br/></code></pre></p><p><strong>Configuration:</strong></p><p><pre><code># config.yaml<br/>regions:<br/>  - us-east-1<br/>  - us-west-2</p><p>accounts:<br/>  123456789012:<br/>    filters:<br/>      # Only delete unattached EBS volumes<br/>      EC2Volume:<br/>        - property: State<br/>          value: available<br/>      # Only delete snapshots older than 90 days<br/>      EC2Snapshot:<br/>        - property: StartDate<br/>          type: older_than<br/>          value: "90d"<br/>      # Never delete production resources<br/>      EC2Instance:<br/>        - or:<br/>            - property: tag:Environment<br/>              value: production<br/>            - property: tag:do-not-delete<br/>              value: "true"<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Dry run (always do this first!)<br/>aws-nuke run --config config.yaml --dry-run</p><p><h1>Actual nuke (be very careful!)</h1><br/>aws-nuke run --config config.yaml --no-dry-run<br/></code></pre></p><p><strong>Pros:</strong><br/><li>Extremely fast and thorough</li><br/><li>Powerful filter system</li><br/><li>Excellent for cleaning up test/dev environments</li></p><p><strong>Cons:</strong><br/><li>Can be dangerous in production</li><br/><li>Requires careful configuration</li><br/><li>Not selective enough for production cleanup</li></p><p><h3>Cloud Custodian</h3></p><p><strong>Cloud Custodian</strong> is a rules engine for managing AWS resources, including automated cleanup. It's more policy-driven than aws-nuke.</p><p><strong>Installation:</strong></p><p><pre><code># Install via pip<br/>pip install custodian</p><p><h1>Or via Homebrew (Mac)</h1><br/>brew install cloud-custodian<br/></code></pre></p><p><strong>Configuration:</strong></p><p><pre><code># cleanup.yml<br/>policies:<br/>  - name: delete-unattached-ebs<br/>    resource: ebs<br/>    filters:<br/>      - type: value<br/>        key: State<br/>        value: available<br/>      - not:<br/>          - type: value<br/>            key: "tag:do-not-delete"<br/>            value: "true"<br/>    actions:<br/>      - type: delete<br/>        # Require confirmation via email<br/>        notify:<br/>          - type: email<br/>            to:<br/>              - ops@company.com</p><p>  - name: delete-old-snapshots<br/>    resource: ebs-snapshot<br/>    filters:<br/>      - type: value<br/>        key: "tag:Age"<br/>        op: greater-than<br/>        value: 90<br/>      - not:<br/>          - type: value<br/>            key: "tag:do-not-delete"<br/>            value: "true"<br/>    actions:<br/>      - type: delete</p><p>  - name: stop-idle-instances<br/>    resource: ec2<br/>    filters:<br/>      - type: metrics<br/>        name: CPUUtilization<br/>        days: 7<br/>        value: 5<br/>        op: less-than<br/>      - not:<br/>          - type: value<br/>            key: "tag:do-not-stop"<br/>            value: "true"<br/>    actions:<br/>      - type: stop</p><p>  - name: release-unused-eips<br/>    resource: network-addr<br/>    filters:<br/>      - type: value<br/>        key: AssociationId<br/>        value: null<br/>      - not:<br/>          - type: value<br/>            key: "tag:do-not-delete"<br/>            value: "true"<br/>    actions:<br/>      - type: release<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Dry run<br/>custodian run cleanup.yml --dry-run</p><p><h1>Run with output to S3 for logging</h1><br/>custodian run cleanup.yml \<br/>  --s3-bucket custodian-logs \<br/>  --region us-east-1</p><p><h1>Schedule with Lambda</h1><br/>custodian run cleanup.yml \<br/>  --output-dir s3://custodian-logs/reports \<br/>  --region us-east-1 \<br/>  --lambda<br/></code></pre></p><p><strong>Pros:</strong><br/><li>Policy-driven, rules-based approach</li><br/><li>Supports multiple clouds (AWS, Azure, GCP)</li><br/><li>Rich filter and action ecosystem</li><br/><li>Can be scheduled with Lambda</li><br/><li>Good for ongoing governance</li></p><p><strong>Cons:</strong><br/><li>YAML configuration can be complex</li><br/><li>Steeper learning curve than simple scripts</li><br/><li>Requires more setup for basic cleanup</li></p><p><h3>Komiser</h3></p><p><strong>Komiser</strong> is a cloud cost monitoring and resource governance tool. It's less about cleanup and more about visibility, but it can help identify waste.</p><p><strong>Installation:</strong></p><p><pre><code># Docker<br/>docker run -d -p 3000:3000 \<br/>  -v $HOME/.komiser:/app/.komiser \<br/>  komiser/komiser:latest</p><p><h1>Or via Homebrew</h1><br/>brew tap komiserhq/komiser<br/>brew install komiser<br/></code></pre></p><p><strong>Configuration:</strong></p><p><pre><code># komiser.yaml<br/>credentials:<br/>  - name: aws-prod<br/>    type: aws<br/>    id: AKIA...<br/>    secret: ...<br/>    source: account<br/>    account: 123456789012</p><p>  - name: gcp-prod<br/>    type: gcp<br/>    source: account<br/>    credentials: /path/to/service-account.json<br/></code></pre></p><p><strong>Usage:</strong></p><p><pre><code># Start dashboard<br/>komiser start</p><p><h1>List all resources</h1><br/>komiser resources --provider aws</p><p><h1>Get cost by service</h1><br/>komiser costs --provider aws --by service</p><p><h1>Get cost by region</h1><br/>komiser costs --provider aws --by region<br/></code></pre></p><p><strong>Komiser Web Dashboard:</strong><br/><li>View all resources across clouds</li><br/><li>Filter by provider, region, service</li><br/><li>Track costs in real-time</li><br/><li>Identify underutilized resources</li></p><p><strong>Pros:</strong><br/><li>Multi-cloud support</li><br/><li>Beautiful web dashboard</li><br/><li>Good for visibility first, cleanup later</li><br/><li>Real-time cost tracking</li></p><p><strong>Cons:</strong><br/><li>Less automated cleanup than Cloud Custodian</li><br/><li>More of a monitoring tool than a cleanup tool</li><br/><li>Requires manual action on findings</li></p><p><h2>$2</h2></p><p>Automated cleanup without safety is dangerous. Here's how to protect production resources.</p><p><h3>Tagging Strategy</h3></p><p><strong>Required Tags:</strong></p><p><pre><code># Environment tag<br/>Environment: production|staging|development</p><p><h1>Owner tag</h1><br/>Owner: team-name or individual-email</p><p><h1>Purpose tag</h1><br/>Purpose: what-the-resource-does</p><p><h1>Exemption tags</h1><br/>do-not-delete: "true"<br/>do-not-stop: "true"<br/>keep: "true"<br/>preserve: "true"<br/></code></pre></p><p><strong>Tag Enforcement:</strong></p><p><pre><code># Cloud Custodian policy to enforce tagging<br/>policies:<br/>  - name: enforce-resource-tagging<br/>    resource: ec2<br/>    filters:<br/>      - or:<br/>          - type: value<br/>            key: "tag:Environment"<br/>            value: absent<br/>          - type: value<br/>            key: "tag:Owner"<br/>            value: absent<br/>          - type: value<br/>            key: "tag:Purpose"<br/>            value: absent<br/>    actions:<br/>      - type: notify<br/>        subject: "Untagged EC2 instance detected"<br/>        to:<br/>          - ops@company.com<br/>      - type: mark-for-op<br/>        op: stop<br/>        days: 7<br/></code></pre></p><p><h3>Dry-Run Mode</h3></p><p>Always implement dry-run mode in your scripts:</p><p><pre><code># Pattern for dry-run<br/>def delete_resource(resource_id, dry_run=True):<br/>    """Delete a resource with dry-run mode."""<br/>    if dry_run:<br/>        print(""<br/>        return False<br/>    else:<br/>        # Actual deletion<br/>        try:<br/>            client.delete(ResourceId=resource_id)<br/>            print(""<br/>            return True<br/>        except Exception as e:<br/>            print(""<br/>            return False</p><p><h1>Require explicit confirmation</h1><br/>if not dry_run:<br/>    confirm = input("This will delete resources. Type 'yes' to confirm: ")<br/>    if confirm.lower() != 'yes':<br/>        sys.exit(0)<br/></code></pre></p><p><h3>Approval Workflows</h3></p><p>For production environments, use approval workflows:</p><p><pre><code># Cloud Custodian with approval<br/>policies:<br/>  - name: delete-unattached-volumes-with-approval<br/>    resource: ebs<br/>    filters:<br/>      - type: value<br/>        key: State<br/>        value: available<br/>    actions:<br/>      - type: notify<br/>        subject: "Unattached EBS volumes found - Approve deletion?"<br/>        template: approval-email.j2<br/>        to:<br/>          - ops@company.com<br/>        transport:<br/>          type: sns<br/>          topic: arn:aws:sns:us-east-1:123456789012:cleanup-approvals<br/></code></pre></p><p>When recipients reply with "APPROVE", a Lambda function triggers the actual deletion.</p><p><h2>$2</h2></p><p>Measure your savings to prove ROI.</p><p><h3>Before Cleanup</h3></p><p><pre><code># Get current monthly cost estimate<br/>aws ce get-cost-and-usage \<br/>  --time-period Start=$(date -u -d '30 days ago' --iso-8601=seconds),End=$(date -u --iso-8601=seconds) \<br/>  --granularity MONTHLY \<br/>  --metrics UnblendedCost \<br/>  --query 'ResultsByTime[0].Total.UnblendedCost' \<br/>  --output text</p><p><h1>Get cost by service</h1><br/>aws ce get-cost-and-usage \<br/>  --time-period Start=$(date -u -d '30 days ago' --iso-8601=seconds),End=$(date -u --iso-8601=seconds) \<br/>  --granularity MONTHLY \<br/>  --metrics UnblendedCost \<br/>  --group-by Type=DIMENSION,Key=SERVICE<br/></code></pre></p><p><h3>After Cleanup</h3></p><p><pre><code># Wait 30 days for data to settle<br/><h1>Then run same queries</h1></p><p><h1>Calculate savings</h1><br/>BEFORE_COST=$(echo "$cost_before")<br/>AFTER_COST=$(echo "$cost_after")<br/>SAVINGS=$(echo "$BEFORE_COST - $AFTER_COST" | bc)<br/>PERCENT=$(echo "$SAVINGS / $BEFORE_COST * 100" | bc -l)</p><p>echo "Before: $\${BEFORE_COST}/month"<br/>echo "After: $\${AFTER_COST}/month"<br/>echo "Savings: $\${SAVINGS}/month (${PERCENT:.1f}%)"<br/></code></pre></p><p><h3>Tracking Script</h3></p><p><pre><code>#!/usr/bin/env python3<br/>"""<br/>Track cost savings from cleanup efforts.<br/>"""</p><p>import boto3<br/>from datetime import datetime, timedelta<br/>import json</p><p>def get_monthly_cost(days=30):<br/>    """Get monthly cost for the last N days."""<br/>    ce = boto3.client('ce')<br/>    <br/>    end_date = datetime.now().strftime('%Y-%m-%d')<br/>    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')<br/>    <br/>    response = ce.get_cost_and_usage(<br/>        TimePeriod={<br/>            'Start': start_date,<br/>            'End': end_date<br/>        },<br/>        Granularity='MONTHLY',<br/>        Metrics=['UnblendedCost']<br/>    )<br/>    <br/>    return float(response['ResultsByTime'][0]['Total']['UnblendedCost']['Amount'])</p><p>def track_cleanup_results():<br/>    """Track and log cleanup results."""<br/>    <br/>    # Load previous costs<br/>    try:<br/>        with open('cleanup_cost_history.json', 'r') as f:<br/>            history = json.load(f)<br/>    except FileNotFoundError:<br/>        history = {'entries': []}<br/>    <br/>    # Get current cost<br/>    current_cost = get_monthly_cost(30)<br/>    <br/>    # Calculate savings<br/>    if history['entries']:<br/>        previous_cost = history['entries'][0]['cost']<br/>        savings = previous_cost - current_cost<br/>        savings_percent = (savings / previous_cost) * 100 if previous_cost > 0 else 0<br/>    else:<br/>        savings = 0<br/>        savings_percent = 0<br/>    <br/>    # Add entry<br/>    entry = {<br/>        'date': datetime.now().isoformat(),<br/>        'cost': current_cost,<br/>        'savings': savings,<br/>        'savings_percent': savings_percent<br/>    }<br/>    history['entries'].insert(0, entry)<br/>    <br/>    # Keep last 12 entries<br/>    history['entries'] = history['entries'][:12]<br/>    <br/>    # Save<br/>    with open('cleanup_cost_history.json', 'w') as f:<br/>        json.dump(history, f, indent=2)<br/>    <br/>    # Print summary<br/>    print(""<br/>    if savings > 0:<br/>        print(""<br/>    <br/>    return entry</p><p>if __name__ == '__main__':<br/>    track_cleanup_results()<br/></code></pre></p><p><h2>$2</h2></p><p>Here are specific savings I've seen from implementing automated cleanup.</p><p><h3>Example 1: Startup with 50 EC2 Instances</h3></p><p><strong>Before:</strong><br/><li>Monthly cost: $8,500</li><br/><li>Issues: 12 idle instances, 30 unattached volumes</li><br/><li>Identified: 38% waste</li></p><p><strong>After cleanup:</strong><br/><li>Stopped 12 idle instances: $2,400/month saved</li><br/><li>Deleted 30 volumes: $600/month saved</li><br/><li>Total savings: $3,000/month (35%)</li></p><p><strong>ROI:</strong><br/><li>Setup time: 16 hours</li><br/><li>Infrastructure cost: $20/month (Lambda + EventBridge)</li><br/><li>Monthly savings: $3,000</li><br/><li>Payback: < 1 week</li></p><p><h3>Example 2: Enterprise with 200 EBS Volumes</h3></p><p><strong>Before:</strong><br/><li>Monthly cost: $15,200</li><br/><li>Issues: 87 unattached volumes (3.2 TB)</li><br/><li>Identified: 21% waste</li></p><p><strong>After cleanup:</strong><br/><li>Deleted 87 unattached volumes: $1,280/month saved</li><br/><li>Implemented 90-day snapshot retention: $450/month saved</li><br/><li>Total savings: $1,730/month (11.4%)</li></p><p><strong>ROI:</strong><br/><li>Setup time: 24 hours</li><br/><li>Infrastructure cost: $30/month</li><br/><li>Monthly savings: $1,730</li><br/><li>Payback: 1 week</li></p><p><h3>Example 3: Dev Environment Auto-Shutdown</h3></p><p><strong>Before:</strong><br/><li>Monthly cost: $4,800</li><br/><li>Issues: Dev runs 24/7, used 8 hours/day</li><br/><li>Identified: 67% runtime waste</li></p><p><strong>After auto-shutdown:</strong><br/><li>Dev shuts down 7 PM - 7 AM: $3,200/month saved</li><br/><li>Weekends off: $1,000/month saved</li><br/><li>Total savings: $4,200/month (87.5%)</li></p><p><strong>ROI:</strong><br/><li>Setup time: 8 hours</li><br/><li>Infrastructure cost: $15/month (Lambda + EventBridge)</li><br/><li>Monthly savings: $4,200</li><br/><li>Payback: < 1 day</li></p><p><h3>Example 4: Snapshot Sprawl Cleanup</h3></p><p><strong>Before:</strong><br/><li>Monthly cost: $22,000</li><br/><li>Issues: 3,500 snapshots, only 150 referenced by AMIs</li><br/><li>Identified: 2.1% waste (but significant in absolute terms)</li></p><p><strong>After cleanup:</strong><br/><li>Deleted 3,350 unreferenced snapshots: $637/month saved</li><br/><li>Implemented 30-day retention: $843/month saved</li><br/><li>Total savings: $1,480/month (6.7%)</li></p><p><strong>ROI:</strong><br/><li>Setup time: 12 hours</li><br/><li>Infrastructure cost: $25/month</li><br/><li>Monthly savings: $1,480</li><br/><li>Payback: 3 days</li></p><p><h2>$2</h2></p><p><h3>Phase 1: Quick Wins (Week 1)</h3></p><p><li>[ ] Enable Cost Explorer</li><br/><li>[ ] Run manual audit of all regions</li><br/><li>[ ] Delete unattached EBS volumes (dry run → confirm → delete)</li><br/><li>[ ] Release unused Elastic IPs</li><br/><li>[ ] Clean old snapshots (>180 days)</li></p><p><strong>Expected savings:</strong> 10-20%</p><p><h3>Phase 2: Automation (Weeks 2-3)</h3></p><p><li>[ ] Implement tagging strategy</li><br/><li>[ ] Deploy EBS cleanup script with dry-run mode</li><br/><li>[ ] Deploy snapshot cleanup script</li><br/><li>[ ] Set up Slack notifications for review</li></p><p><strong>Expected savings:</strong> Additional 5-10%</p><p><h3>Phase 3: Scheduling (Week 4)</h3></p><p><li>[ ] Package cleanup scripts as Lambda functions</li><br/><li>[ ] Create EventBridge rules for weekly execution</li><br/><li>[ ] Implement cost tracking dashboard</li><br/><li>[ ] Set up approval workflow for production</li></p><p><strong>Expected savings:</strong> Ongoing, automatic</p><p><h3>Phase 4: Advanced (Month 2)</h3></p><p><li>[ ] Deploy Cloud Custodian for policy-driven cleanup</li><br/><li>[ ] Set up dev environment auto-shutdown</li><br/><li>[ ] Implement right-sizing recommendations</li><br/><li>[ ] Create FinOps dashboard</li></p><p><strong>Expected savings:</strong> 20-30% total reduction</p><p><h2>$2</h2></p><p><h3>Pitfall 1: Deleting Production Resources</h3></p><p><strong>Problem:</strong> Automated cleanup deletes production resources because they weren't tagged.</p><p><strong>Solution:</strong><br/><li>Implement mandatory tagging</li><br/><li>Use do-not-delete/do-not-stop exemption tags</li><br/><li>Always run dry-run first</li><br/><li>Require approval for production environments</li></p><p><h3>Pitfall 2: Deleting Recently Created Resources</h3></p><p><strong>Problem:</strong> Resources created for testing are deleted before they're deployed.</p><p><strong>Solution:</strong><br/><li>Add age-based filters (e.g., skip resources < 7 days old)</li><br/><li>Use separate cleanup schedules for dev and prod</li><br/><li>Implement staging environment</li></p><p><h3>Pitfall 3: Not Checking Dependencies</h3></p><p><strong>Problem:</strong> Deleting a volume or snapshot breaks an AMI or running instance.</p><p><strong>Solution:</strong><br/><li>Always check AMI references before deleting snapshots</li><br/><li>Verify volumes aren't attached before deletion</li><br/><li>Use Cloud Custodian's dependency checking</li></p><p><h3>Pitfall 4: No Rollback Plan</h3></p><p><strong>Problem:</strong> Something goes wrong and there's no way to recover.</p><p><strong>Solution:</strong><br/><li>Keep backups of critical snapshots</li><br/><li>Document all cleanup actions</li><br/><li>Use CloudTrail for audit logs</li><br/><li>Have a rollback plan for critical resources</li></p><p><h3>Pitfall 5: Not Communicating with Teams</h3></p><p><strong>Problem:</strong> Engineers are surprised when their resources disappear.</p><p><strong>Solution:</strong><br/><li>Send notification emails before cleanup</li><br/><li>Use Slack notifications</li><br/><li>Create a cleanup review process</li><br/><li>Document cleanup policies</li></p><p><h2>$2</h2></p><p>Cloud waste is real, expensive, and cumulative. But it's also solvable.</p><p>The average cloud account wastes 30-40% of its spend on resources that aren't being used. That's not a rounding error—it's millions of dollars annually for mid-sized organizations.</p><p>By implementing automated cleanup, you can:</p><p><li><strong>Eliminate zombie resources</strong>—Unattached volumes, old snapshots, idle instances</li><br/><li><strong>Stop paying for what you don't use</strong>—Dev environments that run 24/7 but are only used 8 hours/day</li><br/><li><strong>Build continuous optimization</strong>—Weekly cleanup that prevents waste from accumulating</li><br/><li><strong>Prove ROI</strong>—Real cost savings you can show to leadership</li></p><p><strong>Key takeaways:</strong></p><p><li><strong>Start with visibility</strong>—Enable Cost Explorer and run a manual audit</li><br/><li><strong>Implement safety first</strong>—Tagging strategy, dry-run mode, approval workflows</li><br/><li><strong>Automate early</strong>—Python scripts → Lambda → EventBridge</li><br/><li><strong>Measure everything</strong>—Track before/after costs to prove ROI</li><br/><li><strong>Iterate continuously</strong>—Cleanup is never "done," it's a process</li></p><p><strong>Your next steps:</strong></p><p><li>Run the manual audit scripts (today)</li><br/><li>Implement the EBS cleanup script (this week)</li><br/><li>Deploy Lambda automation (this month)</li><br/><li>Build toward continuous optimization (ongoing)</li></p><p>Stop paying for what you're not using. Your cloud bill will thank you.</p><p>Built by engineers, for engineers.<br/>    </div><div style="margin-top:5rem;max-width:600px;margin-left:auto;margin-right:auto;background:var(--bg-card);border:1px solid var(--border-subtle);border-radius:24px;padding:3.5rem;position:relative;overflow:hidden;box-shadow:var(--card-shadow)"><div style="position:absolute;top:-2px;left:-2px;right:-2px;bottom:-2px;background:linear-gradient(135deg, var(--accent-cyan), var(--accent-purple), var(--accent-cyan));border-radius:26px;z-index:-1;opacity:0.3"></div><h2 style="font-family:var(--font-space-grotesk);font-size:2rem;font-weight:700;margin-bottom:0.75rem;color:var(--text-primary);position:relative;z-index:1">Get weekly cloud cost tips</h2><p style="color:var(--text-secondary);margin-bottom:2rem;font-size:1rem;line-height:1.8;position:relative;z-index:1">Join engineers saving money on cloud costs. Actionable strategies every Friday.</p><a href="https://sendfox.com/form/3qdz96/36enr2" style="display:inline-block;font-family:var(--font-nunito);font-size:1rem;font-weight:700;padding:1.2rem 2rem;background:linear-gradient(135deg, var(--accent-cyan) 0%, var(--accent-purple) 100%);color:white;border:none;border-radius:12px;cursor:pointer;text-decoration:none;transition:all 0.3s ease;position:relative;z-index:1">Subscribe (free)</a></div></article><footer style="padding:3rem 2rem;text-align:center;border-top:1px solid var(--border-subtle);position:relative;z-index:1;animation:fadeInUp 0.9s ease-out 0.4s both"><p style="font-family:var(--font-nunito);font-size:0.85rem;color:var(--text-muted)">© 2026 Cost Nimbus. Built by engineers, for engineers.</p></footer><!--$--><!--/$--><script src="/_next/static/chunks/7f07730b362b6d01.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[13715,[\"/_next/static/chunks/fa74efd89e4b5edc.js\"],\"default\"]\n3:I[95329,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"default\"]\n4:I[6724,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"default\"]\n6:I[68637,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[68637,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"ViewportBoundary\"]\nb:I[68637,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"MetadataBoundary\"]\nd:I[13248,[],\"default\"]\n:HL[\"/_next/static/chunks/fa45df064ebe4be1.css\",\"style\"]\n:HL[\"/_next/static/media/07454f8ad8aaac57-s.p.fc65572f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/0c89a48fa5027cee-s.p.4564287c.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/70bc3e132a0a741e-s.p.15008bfb.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"87mPO66rg1PfPK5wLJkIl\",\"c\":[\"\",\"article\",\"automated-cloud-resource-cleanup\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"article\",{\"children\":[[\"slug\",\"automated-cloud-resource-cleanup\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/fa45df064ebe4be1.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/fa74efd89e4b5edc.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"space_grotesk_e6988195-module__RNs2Mq__variable nunito_faf8bdde-module__ZdPV6W__variable jetbrains_mono_7ea1d0f9-module__6GV5LG__variable antialiased\",\"style\":{\"fontFamily\":\"var(--font-nunito)\"},\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/432e675556b35c78.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$Lc\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[83207,[\"/_next/static/chunks/fa74efd89e4b5edc.js\",\"/_next/static/chunks/432e675556b35c78.js\"],\"default\"]\nf:Te5e9,"])</script><script>self.__next_f.push([1,"\u003cbr/\u003eThe average cloud account has 30-40% waste. Here's how to find and eliminate it automatically.\u003c/p\u003e\u003cp\u003eIn this guide, I'll show you how to identify zombie resources—unattached EBS volumes, old snapshots, idle instances, forgotten dev environments—and eliminate them with automated cleanup scripts. We'll cover manual audit techniques, Python automation, EventBridge scheduling, and open source tools like aws-nuke and Cloud Custodian.\u003c/p\u003e\u003cp\u003eWhether you're managing a single AWS account or dozens, these strategies will help you stop paying for resources you're not using.\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eCloud waste is silent, cumulative, and expensive. It doesn't happen overnight—it builds over months and years as teams spin up resources, forget them, and move on to the next project.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eThe Numbers\u003c/h3\u003e\u003c/p\u003e\u003cp\u003eLet's start with the reality check:\u003c/p\u003e\u003cp\u003e\u003cli\u003e\u003cstrong\u003e32% of cloud spend\u003c/strong\u003e is wasted on unused resources (industry average)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003e$5.3 billion annually\u003c/strong\u003e wasted on oversized resources alone\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003e$22+ billion\u003c/strong\u003e in global cloud waste per year\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003e40% of instances\u003c/strong\u003e run at less than 5% CPU utilization\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eOrphaned snapshots and volumes\u003c/strong\u003e represent 1-3% of monthly spend without cleanup automation\u003c/li\u003e\u003c/p\u003e\u003cp\u003eThese aren't theoretical numbers from white papers—they're from real audits of production environments.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eReal-World Examples\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCase 1: 500 Unattached EBS Volumes\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eA mid-sized startup had 500 EBS volumes with no attached instances:\u003cbr/\u003e\u003cli\u003eVolume types: 300 gp2, 200 io1\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal size: 2.3 TB\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $1,840\u003c/li\u003e\u003c/p\u003e\u003cp\u003eNone of these volumes were attached to any instance. They were remnants from terminated instances that developers forgot to clean up.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCase 2: 3,000 Old Snapshots\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eAn enterprise had accumulated 3,000 snapshots over 4 years:\u003cbr/\u003e\u003cli\u003eAverage age: 180 days\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal storage: 4.8 TB\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $432\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eProblem: Only 12 snapshots referenced by active AMIs\u003c/li\u003e\u003c/p\u003e\u003cp\u003e88% of snapshots had no purpose—they were just consuming storage and costing money.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCase 3: 200 Unused Elastic IPs\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eA development environment had 200 Elastic IPs not associated with any resource:\u003cbr/\u003e\u003cli\u003eEach EIP: $3.60/month\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $720\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eProblem: These addresses weren't even allocated to running instances\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCase 4: 87 Idle Instances\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eA production environment had 87 EC2 instances running at \u003c5% CPU for 30+ days:\u003cbr/\u003e\u003cli\u003eInstance types: Mix of m5.large, c5.xlarge, r5.2xlarge\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $12,500\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eProblem: These instances were ghost deployments from old projects\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eWhy Zombie Resources Accumulate\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e1. Terminated Instances ≠ Deleted Volumes\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eWhen you terminate an EC2 instance, AWS gives you the option to delete attached volumes. If you don't explicitly select \"Delete on Termination,\" the volume persists.\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Instance terminated\u003cbr/\u003eaws ec2 terminate-instances --instance-ids i-0123456789abcdef0\u003c/p\u003e\u003cp\u003e\u003ch1\u003eBut the volume remains\u003c/h1\u003e\u003cbr/\u003eaws ec2 describe-volumes --filters Name=attachment.instance-id,Values=i-0123456789abcdef0\u003cbr/\u003e\u003ch1\u003eReturns: The volume still exists, still costs money\u003c/h1\u003e\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e2. Snapshot Sprawl\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eEvery backup creates a snapshot. Without retention policies:\u003cbr/\u003e\u003cli\u003eAutomated backups create snapshots daily\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eManual snapshots before deployments\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTesting snapshots that are never deleted\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eOld snapshots with no AMI reference\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e3. Development Environments That Never Sleep\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDev and staging environments often run 24/7 despite only being used during business hours:\u003cbr/\u003e\u003cli\u003eUsage pattern: 8 hours/day, 5 days/week\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eBilling pattern: 24 hours/day, 7 days/week\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eWaste: 67% of runtime cost\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e4. Elastic IPs Without Purpose\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eElastic IPs cost $3.60/month even if not attached. Common causes:\u003cbr/\u003e\u003cli\u003eReleased instances but kept the IP \"just in case\"\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eForgotten load balancers\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTest environments abandoned\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003e5. Oversized Instances\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eRight-sizing issues:\u003cbr/\u003e\u003cli\u003eInitial deployment over-provisioning\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eWorkload changes over time\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMigration from on-prem (resources sized for physical hardware)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\"Better safe than sorry\" mentality\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eBefore automating cleanup, you need to understand what you have. Start with a comprehensive manual audit.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 1: Enable Cost Explorer\u003c/h3\u003e\u003c/p\u003e\u003cp\u003eCost Explorer is your visibility tool—it's free and essential.\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Enable Cost Explorer (one-time setup)\u003cbr/\u003eaws ce enable-ce\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003eOnce enabled, wait 24 hours for data to populate, then:\u003c/p\u003e\u003cp\u003e\u003cli\u003eGo to AWS Console → Cost Management → Cost Explorer\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eCreate a \"Monthly costs by service\" view\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eCreate a \"Daily costs\" view\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eSet up cost anomaly detection\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eCreate budgets for monitoring\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 2: Find Unattached EBS Volumes\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Find all unattached EBS volumes in a region\u003cbr/\u003eaws ec2 describe-volumes \\\u003cbr/\u003e  --filters Name=status,Values=available \\\u003cbr/\u003e  --query 'Volumes[?State==\u003ccode\u003eavailable\u003c/code\u003e].[VolumeId,Size,VolumeType,CreateTime]' \\\u003cbr/\u003e  --output table\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCalculate monthly cost of unattached volumes\u003c/h1\u003e\u003cbr/\u003eaws ec2 describe-volumes \\\u003cbr/\u003e  --filters Name=status,Values=available \\\u003cbr/\u003e  --query 'Volumes[*].[VolumeId,Size,VolumeType]' \\\u003cbr/\u003e  --output json | jq -r '.[] | @csv' | while IFS=, read -r vid size type; do\u003cbr/\u003e    # gp2 pricing: $0.10/GB/month in us-east-1\u003cbr/\u003e    cost=$(echo \"$size * 0.10\" | bc)\u003cbr/\u003e    echo \"$vid,$size,$type,$\\${cost}\"\u003cbr/\u003e  done\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 3: Find Old Snapshots\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Find snapshots older than 90 days\u003cbr/\u003eDATE=$(date -u -d '90 days ago' +%Y-%m-%dT%H:%M:%S)\u003c/p\u003e\u003cp\u003eaws ec2 describe-snapshots \\\u003cbr/\u003e  --owner-ids self \\\u003cbr/\u003e  --filters \"Name=start-time,Values=,\\${DATE}\" \\\u003cbr/\u003e  --query 'Snapshots[*].[SnapshotId,VolumeSize,StartTime,Description]' \\\u003cbr/\u003e  --output table\u003c/p\u003e\u003cp\u003e\u003ch1\u003eFind snapshots not referenced by any AMI\u003c/h1\u003e\u003cbr/\u003eaws ec2 describe-snapshots \\\u003cbr/\u003e  --owner-ids self \\\u003cbr/\u003e  --query 'Snapshots[*].SnapshotId' \\\u003cbr/\u003e  --output text | while read snap_id; do\u003cbr/\u003e    referenced=$(aws ec2 describe-images \\\u003cbr/\u003e      --filters Name=block-device-mapping.snapshot-id,Values=$snap_id \\\u003cbr/\u003e      --query 'Images | length(@)' \\\u003cbr/\u003e      --output text)\u003cbr/\u003e    if [ \"$referenced\" == \"0\" ]; then\u003cbr/\u003e      echo \"$snap_id is not referenced by any AMI\"\u003cbr/\u003e    fi\u003cbr/\u003e  done\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 4: Find Idle EC2 Instances\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Get CPU utilization for all instances over 30 days\u003cbr/\u003eaws cloudwatch get-metric-statistics \\\u003cbr/\u003e  --namespace AWS/EC2 \\\u003cbr/\u003e  --metric-name CPUUtilization \\\u003cbr/\u003e  --dimensions Name=InstanceId,Value=i-0123456789abcdef0 \\\u003cbr/\u003e  --start-time $(date -u -d '30 days ago' --iso-8601=seconds) \\\u003cbr/\u003e  --end-time $(date -u --iso-8601=seconds) \\\u003cbr/\u003e  --period 86400 \\\u003cbr/\u003e  --statistics Average \\\u003cbr/\u003e  --query 'Datapoints[0].Average'\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003eOr use a Python script for all instances (see below).\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 5: Find Unused Elastic IPs\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Find Elastic IPs not associated with any instance\u003cbr/\u003eaws ec2 describe-addresses \\\u003cbr/\u003e  --query 'Addresses[?AssociationId==\u003ccode\u003enull\u003c/code\u003e].[PublicIp,AllocationId]' \\\u003cbr/\u003e  --output table\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCount and calculate cost\u003c/h1\u003e\u003cbr/\u003eunused_eips=$(aws ec2 describe-addresses \\\u003cbr/\u003e  --query 'Addresses[?AssociationId==\u003ccode\u003enull\u003c/code\u003e] | length(@)' \\\u003cbr/\u003e  --output text)\u003c/p\u003e\u003cp\u003emonthly_cost=$(echo \"$unused_eips * 3.60\" | bc)\u003cbr/\u003eecho \"Unused EIPs: $unused_eips\"\u003cbr/\u003eecho \"Monthly cost: $\\${monthly_cost}\"\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 6: Find Unused Lambda Versions\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# List all Lambda functions and their versions\u003cbr/\u003eaws lambda list-functions \\\u003cbr/\u003e  --query 'Functions[*].[FunctionName,Version]' \\\u003cbr/\u003e  --output table\u003c/p\u003e\u003cp\u003e\u003ch1\u003eGet all versions for a specific function\u003c/h1\u003e\u003cbr/\u003eaws lambda list-versions-by-function \\\u003cbr/\u003e  --function-name my-function \\\u003cbr/\u003e  --query 'Versions[*].[Version,LastModified]' \\\u003cbr/\u003e  --output table\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eNow let's build automation that finds and eliminates zombie resources. These scripts are production-ready with safety checks and dry-run modes.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eScript 1: Find and Delete Unattached EBS Volumes\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eEBS Volume Cleanup Script\u003cbr/\u003eFinds and deletes unattached EBS volumes with safety checks.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta\u003cbr/\u003eimport sys\u003c/p\u003e\u003cp\u003edef get_unattached_volumes(dry_run=True):\u003cbr/\u003e    \"\"\"Get all volumes not attached to any instance.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    # Filter for available (unattached) volumes\u003cbr/\u003e    response = ec2.describe_volumes(\u003cbr/\u003e        Filters=[\u003cbr/\u003e            {'Name': 'status', 'Values': ['available']}\u003cbr/\u003e        ]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    volumes = response['Volumes']\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    # Calculate total cost\u003cbr/\u003e    total_size = sum(v['Size'] for v in volumes)\u003cbr/\u003e    # gp2 pricing in us-east-1: $0.10/GB/month\u003cbr/\u003e    monthly_cost = total_size * 0.10\u003cbr/\u003e    \u003cbr/\u003e    print(\"Total size: {} GB\".format(total_size))\u003cbr/\u003e    print(\"Monthly cost: ${:.2f}\".format(monthly_cost))\u003cbr/\u003e    \u003cbr/\u003e    return volumes\u003c/p\u003e\u003cp\u003edef check_tags(volume):\u003cbr/\u003e    \"\"\"Check if volume has exemption tags.\"\"\"\u003cbr/\u003e    tags = volume.get('Tags', [])\u003cbr/\u003e    tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e    \u003cbr/\u003e    # Exempt if any of these tags exist\u003cbr/\u003e    exempt_tags = ['do-not-delete', 'preserve', 'keep', 'exempt']\u003cbr/\u003e    \u003cbr/\u003e    for exempt_tag in exempt_tags:\u003cbr/\u003e        if exempt_tag in tag_dict:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            return True\u003cbr/\u003e    \u003cbr/\u003e    return False\u003c/p\u003e\u003cp\u003edef delete_volume(volume_id, dry_run=True):\u003cbr/\u003e    \"\"\"Delete a volume with safety checks.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    try:\u003cbr/\u003e        if dry_run:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        else:\u003cbr/\u003e            ec2.delete_volume(VolumeId=volume_id)\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        return True\u003cbr/\u003e    except Exception as e:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003c/p\u003e\u003cp\u003edef main():\u003cbr/\u003e    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv\u003cbr/\u003e    force = '--force' in sys.argv or '-f' in sys.argv\u003cbr/\u003e    \u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"DRY RUN MODE - No changes will be made\")\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    else:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"PRODUCTION MODE - Volumes WILL be deleted!\")\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    \u003cbr/\u003e    if not dry_run and not force:\u003cbr/\u003e        confirm = input(\"\\nThis will delete unattached volumes. Continue? (yes/no): \")\u003cbr/\u003e        if confirm.lower() != 'yes':\u003cbr/\u003e            print(\"Aborted.\")\u003cbr/\u003e            sys.exit(0)\u003cbr/\u003e    \u003cbr/\u003e    volumes = get_unattached_volumes(dry_run)\u003cbr/\u003e    \u003cbr/\u003e    if not volumes:\u003cbr/\u003e        print(\"No unattached volumes found.\")\u003cbr/\u003e        return\u003cbr/\u003e    \u003cbr/\u003e    deleted_count = 0\u003cbr/\u003e    exempt_count = 0\u003cbr/\u003e    total_size_deleted = 0\u003cbr/\u003e    \u003cbr/\u003e    for volume in volumes:\u003cbr/\u003e        volume_id = volume['VolumeId']\u003cbr/\u003e        size = volume['Size']\u003cbr/\u003e        create_time = volume['CreateTime']\u003cbr/\u003e        age_days = (datetime.now(create_time.tzinfo) - create_time).days\u003cbr/\u003e        \u003cbr/\u003e        print(\"\"\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        if check_tags(volume):\u003cbr/\u003e            exempt_count += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Additional safety: volumes created in last 7 days\u003cbr/\u003e        if age_days \u003c 7:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            exempt_count += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Delete the volume\u003cbr/\u003e        if delete_volume(volume_id, dry_run):\u003cbr/\u003e            deleted_count += 1\u003cbr/\u003e            total_size_deleted += size\u003cbr/\u003e    \u003cbr/\u003e    print(\"\\n\" + \"=\" * 60)\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    main()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Dry run (safe, see what would be deleted)\u003cbr/\u003epython3 cleanup_ebs.py --dry-run\u003c/p\u003e\u003cp\u003e\u003ch1\u003eProduction run (with confirmation)\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_ebs.py\u003c/p\u003e\u003cp\u003e\u003ch1\u003eProduction run (force, no confirmation)\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_ebs.py --force\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eScript 2: Clean Old Snapshots\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eSnapshot Cleanup Script\u003cbr/\u003eDeletes old snapshots not referenced by any AMI.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta, timezone\u003cbr/\u003eimport sys\u003c/p\u003e\u003cp\u003edef get_old_snapshots(days=90, dry_run=True):\u003cbr/\u003e    \"\"\"Get snapshots older than specified days.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_snapshots(\u003cbr/\u003e        OwnerIds=['self'],\u003cbr/\u003e        Filters=[\u003cbr/\u003e            {'Name': 'start-time', 'Values': [f',\\{cutoff_date.isoformat()}']}\u003cbr/\u003e        ]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    snapshots = response['Snapshots']\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return snapshots\u003c/p\u003e\u003cp\u003edef is_snapshot_referenced(snapshot_id):\u003cbr/\u003e    \"\"\"Check if snapshot is referenced by any AMI.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_images(\u003cbr/\u003e        Filters=[\u003cbr/\u003e            {'Name': 'block-device-mapping.snapshot-id', 'Values': [snapshot_id]}\u003cbr/\u003e        ]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    return len(response['Images']) \u003e 0\u003c/p\u003e\u003cp\u003edef delete_snapshot(snapshot_id, dry_run=True):\u003cbr/\u003e    \"\"\"Delete a snapshot.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    try:\u003cbr/\u003e        if dry_run:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        else:\u003cbr/\u003e            ec2.delete_snapshot(SnapshotId=snapshot_id)\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        return True\u003cbr/\u003e    except Exception as e:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003c/p\u003e\u003cp\u003edef main():\u003cbr/\u003e    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv\u003cbr/\u003e    force = '--force' in sys.argv or '-f' in sys.argv\u003cbr/\u003e    days = int(sys.argv[sys.argv.index('--days') + 1]) if '--days' in sys.argv else 90\u003cbr/\u003e    \u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    else:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    \u003cbr/\u003e    if not dry_run and not force:\u003cbr/\u003e        confirm = input(\"\\nThis will delete old unreferenced snapshots. Continue? (yes/no): \")\u003cbr/\u003e        if confirm.lower() != 'yes':\u003cbr/\u003e            print(\"Aborted.\")\u003cbr/\u003e            sys.exit(0)\u003cbr/\u003e    \u003cbr/\u003e    snapshots = get_old_snapshots(days, dry_run)\u003cbr/\u003e    \u003cbr/\u003e    if not snapshots:\u003cbr/\u003e        print(\"No old snapshots found.\")\u003cbr/\u003e        return\u003cbr/\u003e    \u003cbr/\u003e    deleted_count = 0\u003cbr/\u003e    exempt_count = 0\u003cbr/\u003e    total_size_deleted = 0\u003cbr/\u003e    \u003cbr/\u003e    for snapshot in snapshots:\u003cbr/\u003e        snapshot_id = snapshot['SnapshotId']\u003cbr/\u003e        size = snapshot['VolumeSize']\u003cbr/\u003e        start_time = snapshot['StartTime']\u003cbr/\u003e        description = snapshot.get('Description', '')\u003cbr/\u003e        \u003cbr/\u003e        age_days = (datetime.now(timezone.utc) - start_time).days\u003cbr/\u003e        \u003cbr/\u003e        print(\"\"\u003cbr/\u003e        if description:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        \u003cbr/\u003e        # Check if referenced by AMI\u003cbr/\u003e        if is_snapshot_referenced(snapshot_id):\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            exempt_count += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        tags = snapshot.get('Tags', [])\u003cbr/\u003e        tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e        \u003cbr/\u003e        exempt_tags = ['do-not-delete', 'preserve', 'keep', 'backup']\u003cbr/\u003e        for exempt_tag in exempt_tags:\u003cbr/\u003e            if exempt_tag in tag_dict:\u003cbr/\u003e                print(\"\"\u003cbr/\u003e                exempt_count += 1\u003cbr/\u003e                continue\u003cbr/\u003e        \u003cbr/\u003e        # Delete the snapshot\u003cbr/\u003e        if delete_snapshot(snapshot_id, dry_run):\u003cbr/\u003e            deleted_count += 1\u003cbr/\u003e            total_size_deleted += size\u003cbr/\u003e    \u003cbr/\u003e    print(\"\\n\" + \"=\" * 60)\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    # Snapshot pricing in us-east-1: $0.05/GB/month\u003cbr/\u003e    print(\"\"\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    main()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Dry run for snapshots older than 90 days\u003cbr/\u003epython3 cleanup_snapshots.py --dry-run --days 90\u003c/p\u003e\u003cp\u003e\u003ch1\u003eDelete snapshots older than 180 days\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_snapshots.py --days 180\u003c/p\u003e\u003cp\u003e\u003ch1\u003eForce delete (no confirmation)\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_snapshots.py --days 90 --force\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eScript 3: Stop Idle EC2 Instances\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eIdle EC2 Instance Cleanup\u003cbr/\u003eStops instances with CPU \u003c 5% for 7+ days.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta, timezone\u003cbr/\u003eimport sys\u003c/p\u003e\u003cp\u003edef get_instance_cpu(instance_id, days=7):\u003cbr/\u003e    \"\"\"Get average CPU utilization for an instance.\"\"\"\u003cbr/\u003e    cloudwatch = boto3.client('cloudwatch')\u003cbr/\u003e    \u003cbr/\u003e    end_time = datetime.now(timezone.utc)\u003cbr/\u003e    start_time = end_time - timedelta(days=days)\u003cbr/\u003e    \u003cbr/\u003e    response = cloudwatch.get_metric_statistics(\u003cbr/\u003e        Namespace='AWS/EC2',\u003cbr/\u003e        MetricName='CPUUtilization',\u003cbr/\u003e        Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],\u003cbr/\u003e        StartTime=start_time,\u003cbr/\u003e        EndTime=end_time,\u003cbr/\u003e        Period=86400,  # Daily\u003cbr/\u003e        Statistics=['Average']\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    datapoints = response['Datapoints']\u003cbr/\u003e    if not datapoints:\u003cbr/\u003e        return None\u003cbr/\u003e    \u003cbr/\u003e    avg_cpu = sum(dp['Average'] for dp in datapoints) / len(datapoints)\u003cbr/\u003e    return avg_cpu\u003c/p\u003e\u003cp\u003edef check_instance_tags(instance):\u003cbr/\u003e    \"\"\"Check if instance has exemption tags.\"\"\"\u003cbr/\u003e    tags = instance.get('Tags', [])\u003cbr/\u003e    tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e    \u003cbr/\u003e    exempt_tags = ['do-not-stop', 'always-on', 'production', 'critical']\u003cbr/\u003e    \u003cbr/\u003e    for exempt_tag in exempt_tags:\u003cbr/\u003e        if exempt_tag.lower() in [k.lower() for k in tag_dict.keys()]:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            return True\u003cbr/\u003e    \u003cbr/\u003e    return False\u003c/p\u003e\u003cp\u003edef stop_instance(instance_id, dry_run=True):\u003cbr/\u003e    \"\"\"Stop an EC2 instance.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    try:\u003cbr/\u003e        if dry_run:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        else:\u003cbr/\u003e            ec2.stop_instances(InstanceIds=[instance_id])\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        return True\u003cbr/\u003e    except Exception as e:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003c/p\u003e\u003cp\u003edef main():\u003cbr/\u003e    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv\u003cbr/\u003e    force = '--force' in sys.argv or '-f' in sys.argv\u003cbr/\u003e    cpu_threshold = float(sys.argv[sys.argv.index('--cpu') + 1]) if '--cpu' in sys.argv else 5.0\u003cbr/\u003e    days = int(sys.argv[sys.argv.index('--days') + 1]) if '--days' in sys.argv else 7\u003cbr/\u003e    \u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    # Get all running instances\u003cbr/\u003e    response = ec2.describe_instances(\u003cbr/\u003e        Filters=[\u003cbr/\u003e            {'Name': 'instance-state-name', 'Values': ['running']}\u003cbr/\u003e        ]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    instances = []\u003cbr/\u003e    for reservation in response['Reservations']:\u003cbr/\u003e        instances.extend(reservation['Instances'])\u003cbr/\u003e    \u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"DRY RUN MODE - No instances will be stopped\")\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    else:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"PRODUCTION MODE - Instances WILL be stopped!\")\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    \u003cbr/\u003e    if not dry_run and not force:\u003cbr/\u003e        confirm = input(\"\\nThis will stop idle instances. Continue? (yes/no): \")\u003cbr/\u003e        if confirm.lower() != 'yes':\u003cbr/\u003e            print(\"Aborted.\")\u003cbr/\u003e            sys.exit(0)\u003cbr/\u003e    \u003cbr/\u003e    stopped_count = 0\u003cbr/\u003e    exempt_count = 0\u003cbr/\u003e    \u003cbr/\u003e    for instance in instances:\u003cbr/\u003e        instance_id = instance['InstanceId']\u003cbr/\u003e        instance_type = instance['InstanceType']\u003cbr/\u003e        launch_time = instance['LaunchTime']\u003cbr/\u003e        \u003cbr/\u003e        # Skip instances launched in last 30 days\u003cbr/\u003e        age_days = (datetime.now(timezone.utc) - launch_time).days\u003cbr/\u003e        if age_days \u003c 30:\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Get CPU utilization\u003cbr/\u003e        avg_cpu = get_instance_cpu(instance_id, days)\u003cbr/\u003e        \u003cbr/\u003e        if avg_cpu is None:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        \u003cbr/\u003e        if avg_cpu \u003e= cpu_threshold:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        if check_instance_tags(instance):\u003cbr/\u003e            exempt_count += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Stop the instance\u003cbr/\u003e        if stop_instance(instance_id, dry_run):\u003cbr/\u003e            stopped_count += 1\u003cbr/\u003e    \u003cbr/\u003e    print(\"\\n\" + \"=\" * 60)\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    main()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Dry run: find instances with CPU \u003c 5% for 7 days\u003cbr/\u003epython3 cleanup_instances.py --dry-run --cpu 5.0 --days 7\u003c/p\u003e\u003cp\u003e\u003ch1\u003eStop instances with CPU \u003c 3% for 14 days\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_instances.py --cpu 3.0 --days 14\u003c/p\u003e\u003cp\u003e\u003ch1\u003eForce stop (no confirmation)\u003c/h1\u003e\u003cbr/\u003epython3 cleanup_instances.py --cpu 5.0 --days 7 --force\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eScript 4: Delete Unused Elastic IPs\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eElastic IP Cleanup Script\u003cbr/\u003eReleases Elastic IPs not associated with any resource.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003eimport sys\u003c/p\u003e\u003cp\u003edef get_unused_eips(dry_run=True):\u003cbr/\u003e    \"\"\"Get Elastic IPs not associated with any instance.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_addresses()\u003cbr/\u003e    \u003cbr/\u003e    unused_eips = [\u003cbr/\u003e        addr for addr in response['Addresses']\u003cbr/\u003e        if addr.get('AssociationId') is None\u003cbr/\u003e    ]\u003cbr/\u003e    \u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return unused_eips\u003c/p\u003e\u003cp\u003edef check_tags(address):\u003cbr/\u003e    \"\"\"Check if address has exemption tags.\"\"\"\u003cbr/\u003e    tags = address.get('Tags', [])\u003cbr/\u003e    tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e    \u003cbr/\u003e    exempt_tags = ['do-not-delete', 'preserve', 'keep']\u003cbr/\u003e    \u003cbr/\u003e    for exempt_tag in exempt_tags:\u003cbr/\u003e        if exempt_tag in tag_dict:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            return True\u003cbr/\u003e    \u003cbr/\u003e    return False\u003c/p\u003e\u003cp\u003edef release_eip(allocation_id, dry_run=True):\u003cbr/\u003e    \"\"\"Release an Elastic IP.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    try:\u003cbr/\u003e        if dry_run:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        else:\u003cbr/\u003e            ec2.release_address(AllocationId=allocation_id)\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        return True\u003cbr/\u003e    except Exception as e:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003c/p\u003e\u003cp\u003edef main():\u003cbr/\u003e    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv\u003cbr/\u003e    force = '--force' in sys.argv or '-f' in sys.argv\u003cbr/\u003e    \u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"DRY RUN MODE - No EIPs will be released\")\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    else:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"PRODUCTION MODE - EIPs WILL be released!\")\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    \u003cbr/\u003e    if not dry_run and not force:\u003cbr/\u003e        confirm = input(\"\\nThis will release unused Elastic IPs. Continue? (yes/no): \")\u003cbr/\u003e        if confirm.lower() != 'yes':\u003cbr/\u003e            print(\"Aborted.\")\u003cbr/\u003e            sys.exit(0)\u003cbr/\u003e    \u003cbr/\u003e    eips = get_unused_eips(dry_run)\u003cbr/\u003e    \u003cbr/\u003e    if not eips:\u003cbr/\u003e        print(\"No unused Elastic IPs found.\")\u003cbr/\u003e        return\u003cbr/\u003e    \u003cbr/\u003e    released_count = 0\u003cbr/\u003e    exempt_count = 0\u003cbr/\u003e    \u003cbr/\u003e    for addr in eips:\u003cbr/\u003e        public_ip = addr['PublicIp']\u003cbr/\u003e        allocation_id = addr['AllocationId']\u003cbr/\u003e        \u003cbr/\u003e        print(\"\"\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        if check_tags(addr):\u003cbr/\u003e            exempt_count += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Release the address\u003cbr/\u003e        if release_eip(allocation_id, dry_run):\u003cbr/\u003e            released_count += 1\u003cbr/\u003e    \u003cbr/\u003e    print(\"\\n\" + \"=\" * 60)\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    main()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eScript 5: Clean Old Lambda Versions\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eLambda Version Cleanup Script\u003cbr/\u003eDeletes old versions of Lambda functions.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta, timezone\u003cbr/\u003eimport sys\u003c/p\u003e\u003cp\u003edef get_lambda_versions(function_name, keep_versions=5, dry_run=True):\u003cbr/\u003e    \"\"\"Get old versions of a Lambda function.\"\"\"\u003cbr/\u003e    lambda_client = boto3.client('lambda')\u003cbr/\u003e    \u003cbr/\u003e    response = lambda_client.list_versions_by_function(\u003cbr/\u003e        FunctionName=function_name\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    versions = response['Versions']\u003cbr/\u003e    \u003cbr/\u003e    # Sort by last modified (newest first)\u003cbr/\u003e    versions.sort(key=lambda v: v.get('LastModified', datetime.now(timezone.utc)), reverse=True)\u003cbr/\u003e    \u003cbr/\u003e    # Keep the latest versions\u003cbr/\u003e    versions_to_delete = versions[keep_versions:]\u003cbr/\u003e    \u003cbr/\u003e    if versions_to_delete:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return versions_to_delete\u003c/p\u003e\u003cp\u003edef delete_lambda_version(function_name, version, dry_run=True):\u003cbr/\u003e    \"\"\"Delete a specific Lambda version.\"\"\"\u003cbr/\u003e    lambda_client = boto3.client('lambda')\u003cbr/\u003e    \u003cbr/\u003e    try:\u003cbr/\u003e        if dry_run:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        else:\u003cbr/\u003e            lambda_client.delete_function(\u003cbr/\u003e                FunctionName=function_name,\u003cbr/\u003e                Qualifier=version\u003cbr/\u003e            )\u003cbr/\u003e            print(\"\"\u003cbr/\u003e        return True\u003cbr/\u003e    except Exception as e:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003c/p\u003e\u003cp\u003edef main():\u003cbr/\u003e    dry_run = '--dry-run' in sys.argv or '-d' in sys.argv\u003cbr/\u003e    force = '--force' in sys.argv or '-f' in sys.argv\u003cbr/\u003e    keep_versions = int(sys.argv[sys.argv.index('--keep') + 1]) if '--keep' in sys.argv else 5\u003cbr/\u003e    \u003cbr/\u003e    lambda_client = boto3.client('lambda')\u003cbr/\u003e    \u003cbr/\u003e    # Get all Lambda functions\u003cbr/\u003e    response = lambda_client.list_functions()\u003cbr/\u003e    \u003cbr/\u003e    functions = [func['FunctionName'] for func in response['Functions']]\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"DRY RUN MODE - No versions will be deleted\")\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    else:\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e        print(\"PRODUCTION MODE - Versions WILL be deleted!\")\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        print(\"=\" * 60)\u003cbr/\u003e    \u003cbr/\u003e    if not dry_run and not force:\u003cbr/\u003e        confirm = input(\"\\nThis will delete old Lambda versions. Continue? (yes/no): \")\u003cbr/\u003e        if confirm.lower() != 'yes':\u003cbr/\u003e            print(\"Aborted.\")\u003cbr/\u003e            sys.exit(0)\u003cbr/\u003e    \u003cbr/\u003e    deleted_count = 0\u003cbr/\u003e    \u003cbr/\u003e    for function_name in functions:\u003cbr/\u003e        old_versions = get_lambda_versions(function_name, keep_versions, dry_run)\u003cbr/\u003e        \u003cbr/\u003e        for version in old_versions:\u003cbr/\u003e            version_num = version['Version']\u003cbr/\u003e            \u003cbr/\u003e            # Never delete $LATEST\u003cbr/\u003e            if version_num == '$LATEST':\u003cbr/\u003e                continue\u003cbr/\u003e            \u003cbr/\u003e            if delete_lambda_version(function_name, version_num, dry_run):\u003cbr/\u003e                deleted_count += 1\u003cbr/\u003e    \u003cbr/\u003e    print(\"\\n\" + \"=\" * 60)\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    print(\"\"\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    main()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eManual scripts are great, but automated is better. Let's set up scheduled cleanup using EventBridge and Lambda.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 1: Create IAM Role for Lambda\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Create IAM policy for cleanup\u003cbr/\u003ecat \u003e cleanup-policy.json \u003c\u003c'EOF'\u003cbr/\u003e{\u003cbr/\u003e  \"Version\": \"2012-10-17\",\u003cbr/\u003e  \"Statement\": [\u003cbr/\u003e    {\u003cbr/\u003e      \"Effect\": \"Allow\",\u003cbr/\u003e      \"Action\": [\u003cbr/\u003e        \"ec2:DescribeVolumes\",\u003cbr/\u003e        \"ec2:DeleteVolume\",\u003cbr/\u003e        \"ec2:DescribeSnapshots\",\u003cbr/\u003e        \"ec2:DeleteSnapshot\",\u003cbr/\u003e        \"ec2:DescribeInstances\",\u003cbr/\u003e        \"ec2:StopInstances\",\u003cbr/\u003e        \"ec2:DescribeAddresses\",\u003cbr/\u003e        \"ec2:ReleaseAddress\",\u003cbr/\u003e        \"cloudwatch:GetMetricStatistics\"\u003cbr/\u003e      ],\u003cbr/\u003e      \"Resource\": \"*\"\u003cbr/\u003e    }\u003cbr/\u003e  ]\u003cbr/\u003e}\u003cbr/\u003eEOF\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCreate policy\u003c/h1\u003e\u003cbr/\u003eaws iam create-policy \\\u003cbr/\u003e  --policy-name LambdaCleanupPolicy \\\u003cbr/\u003e  --policy-document file://cleanup-policy.json\u003c/p\u003e\u003cp\u003e\u003ch1\u003eGet policy ARN\u003c/h1\u003e\u003cbr/\u003ePOLICY_ARN=$(aws iam list-policies \\\u003cbr/\u003e  --query \"Policies[?PolicyName=='LambdaCleanupPolicy'].Arn\" \\\u003cbr/\u003e  --output text)\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCreate IAM role\u003c/h1\u003e\u003cbr/\u003ecat \u003e trust-policy.json \u003c\u003c'EOF'\u003cbr/\u003e{\u003cbr/\u003e  \"Version\": \"2012-10-17\",\u003cbr/\u003e  \"Statement\": [\u003cbr/\u003e    {\u003cbr/\u003e      \"Effect\": \"Allow\",\u003cbr/\u003e      \"Principal\": {\u003cbr/\u003e        \"Service\": \"lambda.amazonaws.com\"\u003cbr/\u003e      },\u003cbr/\u003e      \"Action\": \"sts:AssumeRole\"\u003cbr/\u003e    }\u003cbr/\u003e  ]\u003cbr/\u003e}\u003cbr/\u003eEOF\u003c/p\u003e\u003cp\u003eaws iam create-role \\\u003cbr/\u003e  --role-name LambdaCleanupRole \\\u003cbr/\u003e  --assume-role-policy-document file://trust-policy.json\u003c/p\u003e\u003cp\u003e\u003ch1\u003eAttach policy to role\u003c/h1\u003e\u003cbr/\u003eaws iam attach-role-policy \\\u003cbr/\u003e  --role-name LambdaCleanupRole \\\u003cbr/\u003e  --policy-arn $POLICY_ARN\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 2: Create Lambda Function\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# lambda_handler.py\u003cbr/\u003eimport json\u003cbr/\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta, timezone\u003c/p\u003e\u003cp\u003edef lambda_handler(event, context):\u003cbr/\u003e    \"\"\"Lambda handler for scheduled cleanup.\"\"\"\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    # Get configuration from event\u003cbr/\u003e    config = event.get('config', {})\u003cbr/\u003e    \u003cbr/\u003e    results = {\u003cbr/\u003e        'timestamp': datetime.now(timezone.utc).isoformat(),\u003cbr/\u003e        'cleanup_tasks': []\u003cbr/\u003e    }\u003cbr/\u003e    \u003cbr/\u003e    # EBS Volume Cleanup\u003cbr/\u003e    if config.get('cleanup_ebs', False):\u003cbr/\u003e        result = cleanup_ebs(dry_run=config.get('dry_run', False))\u003cbr/\u003e        results['cleanup_tasks'].append({\u003cbr/\u003e            'task': 'cleanup_ebs',\u003cbr/\u003e            'result': result\u003cbr/\u003e        })\u003cbr/\u003e    \u003cbr/\u003e    # Snapshot Cleanup\u003cbr/\u003e    if config.get('cleanup_snapshots', False):\u003cbr/\u003e        result = cleanup_snapshots(\u003cbr/\u003e            days=config.get('snapshot_days', 90),\u003cbr/\u003e            dry_run=config.get('dry_run', False)\u003cbr/\u003e        )\u003cbr/\u003e        results['cleanup_tasks'].append({\u003cbr/\u003e            'task': 'cleanup_snapshots',\u003cbr/\u003e            'result': result\u003cbr/\u003e        })\u003cbr/\u003e    \u003cbr/\u003e    # EC2 Instance Cleanup\u003cbr/\u003e    if config.get('cleanup_instances', False):\u003cbr/\u003e        result = cleanup_instances(\u003cbr/\u003e            cpu_threshold=config.get('cpu_threshold', 5.0),\u003cbr/\u003e            days=config.get('instance_days', 7),\u003cbr/\u003e            dry_run=config.get('dry_run', False)\u003cbr/\u003e        )\u003cbr/\u003e        results['cleanup_tasks'].append({\u003cbr/\u003e            'task': 'cleanup_instances',\u003cbr/\u003e            'result': result\u003cbr/\u003e        })\u003cbr/\u003e    \u003cbr/\u003e    print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return {\u003cbr/\u003e        'statusCode': 200,\u003cbr/\u003e        'body': json.dumps(results)\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003edef cleanup_ebs(dry_run=True):\u003cbr/\u003e    \"\"\"Cleanup unattached EBS volumes.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_volumes(\u003cbr/\u003e        Filters=[{'Name': 'status', 'Values': ['available']}]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    volumes = response['Volumes']\u003cbr/\u003e    deleted = 0\u003cbr/\u003e    exempted = 0\u003cbr/\u003e    size_deleted = 0\u003cbr/\u003e    \u003cbr/\u003e    for volume in volumes:\u003cbr/\u003e        volume_id = volume['VolumeId']\u003cbr/\u003e        tags = volume.get('Tags', [])\u003cbr/\u003e        tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        if any(tag in tag_dict for tag in ['do-not-delete', 'preserve', 'keep']):\u003cbr/\u003e            exempted += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        try:\u003cbr/\u003e            if not dry_run:\u003cbr/\u003e                ec2.delete_volume(VolumeId=volume_id)\u003cbr/\u003e            deleted += 1\u003cbr/\u003e            size_deleted += volume['Size']\u003cbr/\u003e        except Exception as e:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return {\u003cbr/\u003e        'deleted': deleted,\u003cbr/\u003e        'exempted': exempted,\u003cbr/\u003e        'size_gb': size_deleted\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003edef cleanup_snapshots(days=90, dry_run=True):\u003cbr/\u003e    \"\"\"Cleanup old unreferenced snapshots.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    \u003cbr/\u003e    cutoff = datetime.now(timezone.utc) - timedelta(days=days)\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_snapshots(\u003cbr/\u003e        OwnerIds=['self'],\u003cbr/\u003e        Filters=[\u003cbr/\u003e            {'Name': 'start-time', 'Values': [f',\\{cutoff.isoformat()}']}\u003cbr/\u003e        ]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    snapshots = response['Snapshots']\u003cbr/\u003e    deleted = 0\u003cbr/\u003e    exempted = 0\u003cbr/\u003e    size_deleted = 0\u003cbr/\u003e    \u003cbr/\u003e    for snapshot in snapshots:\u003cbr/\u003e        snapshot_id = snapshot['SnapshotId']\u003cbr/\u003e        \u003cbr/\u003e        # Check if referenced by AMI\u003cbr/\u003e        ami_response = ec2.describe_images(\u003cbr/\u003e            Filters=[\u003cbr/\u003e                {'Name': 'block-device-mapping.snapshot-id', 'Values': [snapshot_id]}\u003cbr/\u003e            ]\u003cbr/\u003e        )\u003cbr/\u003e        \u003cbr/\u003e        if len(ami_response['Images']) \u003e 0:\u003cbr/\u003e            exempted += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        try:\u003cbr/\u003e            if not dry_run:\u003cbr/\u003e                ec2.delete_snapshot(SnapshotId=snapshot_id)\u003cbr/\u003e            deleted += 1\u003cbr/\u003e            size_deleted += snapshot['VolumeSize']\u003cbr/\u003e        except Exception as e:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return {\u003cbr/\u003e        'deleted': deleted,\u003cbr/\u003e        'exempted': exempted,\u003cbr/\u003e        'size_gb': size_deleted\u003cbr/\u003e    }\u003c/p\u003e\u003cp\u003edef cleanup_instances(cpu_threshold=5.0, days=7, dry_run=True):\u003cbr/\u003e    \"\"\"Cleanup idle EC2 instances.\"\"\"\u003cbr/\u003e    ec2 = boto3.client('ec2')\u003cbr/\u003e    cloudwatch = boto3.client('cloudwatch')\u003cbr/\u003e    \u003cbr/\u003e    response = ec2.describe_instances(\u003cbr/\u003e        Filters=[{'Name': 'instance-state-name', 'Values': ['running']}]\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    instances = []\u003cbr/\u003e    for reservation in response['Reservations']:\u003cbr/\u003e        instances.extend(reservation['Instances'])\u003cbr/\u003e    \u003cbr/\u003e    stopped = 0\u003cbr/\u003e    exempted = 0\u003cbr/\u003e    \u003cbr/\u003e    for instance in instances:\u003cbr/\u003e        instance_id = instance['InstanceId']\u003cbr/\u003e        \u003cbr/\u003e        # Check exemption tags\u003cbr/\u003e        tags = instance.get('Tags', [])\u003cbr/\u003e        tag_dict = {tag['Key']: tag['Value'] for tag in tags}\u003cbr/\u003e        \u003cbr/\u003e        if any(tag.lower() in [k.lower() for k in tag_dict.keys()] \u003cbr/\u003e               for tag in ['do-not-stop', 'always-on', 'production']):\u003cbr/\u003e            exempted += 1\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        # Get CPU\u003cbr/\u003e        end_time = datetime.now(timezone.utc)\u003cbr/\u003e        start_time = end_time - timedelta(days=days)\u003cbr/\u003e        \u003cbr/\u003e        metrics_response = cloudwatch.get_metric_statistics(\u003cbr/\u003e            Namespace='AWS/EC2',\u003cbr/\u003e            MetricName='CPUUtilization',\u003cbr/\u003e            Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],\u003cbr/\u003e            StartTime=start_time,\u003cbr/\u003e            EndTime=end_time,\u003cbr/\u003e            Period=86400,\u003cbr/\u003e            Statistics=['Average']\u003cbr/\u003e        )\u003cbr/\u003e        \u003cbr/\u003e        datapoints = metrics_response['Datapoints']\u003cbr/\u003e        if not datapoints:\u003cbr/\u003e            continue\u003cbr/\u003e        \u003cbr/\u003e        avg_cpu = sum(dp['Average'] for dp in datapoints) / len(datapoints)\u003cbr/\u003e        \u003cbr/\u003e        if avg_cpu \u003c cpu_threshold:\u003cbr/\u003e            try:\u003cbr/\u003e                if not dry_run:\u003cbr/\u003e                    ec2.stop_instances(InstanceIds=[instance_id])\u003cbr/\u003e                stopped += 1\u003cbr/\u003e            except Exception as e:\u003cbr/\u003e                print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return {\u003cbr/\u003e        'stopped': stopped,\u003cbr/\u003e        'exempted': exempted\u003cbr/\u003e    }\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 3: Package and Deploy Lambda\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Create deployment package\u003cbr/\u003ezip lambda_cleanup.zip lambda_handler.py\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCreate Lambda function\u003c/h1\u003e\u003cbr/\u003eaws lambda create-function \\\u003cbr/\u003e  --function-name cloud-cleanup \\\u003cbr/\u003e  --runtime python3.11 \\\u003cbr/\u003e  --role arn:aws:iam::123456789012:role/LambdaCleanupRole \\\u003cbr/\u003e  --handler lambda_handler.lambda_handler \\\u003cbr/\u003e  --zip-file fileb://lambda_cleanup.zip \\\u003cbr/\u003e  --timeout 300 \\\u003cbr/\u003e  --memory-size 512\u003c/p\u003e\u003cp\u003e\u003ch1\u003eUpdate function (for later updates)\u003c/h1\u003e\u003cbr/\u003eaws lambda update-function-code \\\u003cbr/\u003e  --function-name cloud-cleanup \\\u003cbr/\u003e  --zip-file fileb://lambda_cleanup.zip\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 4: Create EventBridge Rule\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Create EventBridge rule (weekly cleanup, Monday 2 AM UTC)\u003cbr/\u003eaws events put-rule \\\u003cbr/\u003e  --name weekly-cloud-cleanup \\\u003cbr/\u003e  --schedule-expression 'cron(0 2 ? * MON *)' \\\u003cbr/\u003e  --description 'Weekly cloud resource cleanup'\u003c/p\u003e\u003cp\u003e\u003ch1\u003eAdd Lambda as target\u003c/h1\u003e\u003cbr/\u003eaws lambda add-permission \\\u003cbr/\u003e  --function-name cloud-cleanup \\\u003cbr/\u003e  --statement-id events-invoke \\\u003cbr/\u003e  --action lambda:InvokeFunction \\\u003cbr/\u003e  --principal events.amazonaws.com \\\u003cbr/\u003e  --source-arn arn:aws:events:us-east-1:123456789012:rule/weekly-cloud-cleanup\u003c/p\u003e\u003cp\u003eaws events put-targets \\\u003cbr/\u003e  --rule weekly-cloud-cleanup \\\u003cbr/\u003e  --targets '{\u003cbr/\u003e    \"Id\": \"1\",\u003cbr/\u003e    \"Arn\": \"arn:aws:lambda:us-east-1:123456789012:function:cloud-cleanup\",\u003cbr/\u003e    \"Input\": \"{\u003cbr/\u003e      \\\"config\\\": {\u003cbr/\u003e        \\\"cleanup_ebs\\\": true,\u003cbr/\u003e        \\\"cleanup_snapshots\\\": true,\u003cbr/\u003e        \\\"cleanup_instances\\\": true,\u003cbr/\u003e        \\\"dry_run\\\": false,\u003cbr/\u003e        \\\"snapshot_days\\\": 90,\u003cbr/\u003e        \\\"cpu_threshold\\\": 5.0,\u003cbr/\u003e        \\\"instance_days\\\": 7\u003cbr/\u003e      }\u003cbr/\u003e    }\"\u003cbr/\u003e  }'\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eStep 5: Test Lambda Invocation\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Test invocation (dry run)\u003cbr/\u003eaws lambda invoke \\\u003cbr/\u003e  --function-name cloud-cleanup \\\u003cbr/\u003e  --payload '{\u003cbr/\u003e    \"config\": {\u003cbr/\u003e      \"cleanup_ebs\": true,\u003cbr/\u003e      \"cleanup_snapshots\": true,\u003cbr/\u003e      \"cleanup_instances\": true,\u003cbr/\u003e      \"dry_run\": true\u003cbr/\u003e    }\u003cbr/\u003e  }' \\\u003cbr/\u003e  response.json\u003c/p\u003e\u003cp\u003e\u003ch1\u003eView logs\u003c/h1\u003e\u003cbr/\u003eaws logs tail /aws/lambda/cloud-cleanup --follow\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eCustom scripts are powerful, but mature open source tools offer more features and community support.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eaws-nuke\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eaws-nuke\u003c/strong\u003e is a tool for cleaning up AWS accounts by nuking (deleting) all resources. It's designed for cleaning up test accounts or entire environments.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eInstallation:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Download latest release\u003cbr/\u003ecurl -L https://github.com/rebuy-de/aws-nuke/releases/download/v3.30.0/aws-nuke-v3.30.0-linux-amd64.tar.gz | tar xz\u003c/p\u003e\u003cp\u003e\u003ch1\u003eMove to PATH\u003c/h1\u003e\u003cbr/\u003esudo mv aws-nuke-v3.30.0-linux-amd64 /usr/local/bin/aws-nuke\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eConfiguration:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# config.yaml\u003cbr/\u003eregions:\u003cbr/\u003e  - us-east-1\u003cbr/\u003e  - us-west-2\u003c/p\u003e\u003cp\u003eaccounts:\u003cbr/\u003e  123456789012:\u003cbr/\u003e    filters:\u003cbr/\u003e      # Only delete unattached EBS volumes\u003cbr/\u003e      EC2Volume:\u003cbr/\u003e        - property: State\u003cbr/\u003e          value: available\u003cbr/\u003e      # Only delete snapshots older than 90 days\u003cbr/\u003e      EC2Snapshot:\u003cbr/\u003e        - property: StartDate\u003cbr/\u003e          type: older_than\u003cbr/\u003e          value: \"90d\"\u003cbr/\u003e      # Never delete production resources\u003cbr/\u003e      EC2Instance:\u003cbr/\u003e        - or:\u003cbr/\u003e            - property: tag:Environment\u003cbr/\u003e              value: production\u003cbr/\u003e            - property: tag:do-not-delete\u003cbr/\u003e              value: \"true\"\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Dry run (always do this first!)\u003cbr/\u003eaws-nuke run --config config.yaml --dry-run\u003c/p\u003e\u003cp\u003e\u003ch1\u003eActual nuke (be very careful!)\u003c/h1\u003e\u003cbr/\u003eaws-nuke run --config config.yaml --no-dry-run\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePros:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eExtremely fast and thorough\u003c/li\u003e\u003cbr/\u003e\u003cli\u003ePowerful filter system\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eExcellent for cleaning up test/dev environments\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCons:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eCan be dangerous in production\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eRequires careful configuration\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eNot selective enough for production cleanup\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eCloud Custodian\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCloud Custodian\u003c/strong\u003e is a rules engine for managing AWS resources, including automated cleanup. It's more policy-driven than aws-nuke.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eInstallation:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Install via pip\u003cbr/\u003epip install custodian\u003c/p\u003e\u003cp\u003e\u003ch1\u003eOr via Homebrew (Mac)\u003c/h1\u003e\u003cbr/\u003ebrew install cloud-custodian\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eConfiguration:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# cleanup.yml\u003cbr/\u003epolicies:\u003cbr/\u003e  - name: delete-unattached-ebs\u003cbr/\u003e    resource: ebs\u003cbr/\u003e    filters:\u003cbr/\u003e      - type: value\u003cbr/\u003e        key: State\u003cbr/\u003e        value: available\u003cbr/\u003e      - not:\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:do-not-delete\"\u003cbr/\u003e            value: \"true\"\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: delete\u003cbr/\u003e        # Require confirmation via email\u003cbr/\u003e        notify:\u003cbr/\u003e          - type: email\u003cbr/\u003e            to:\u003cbr/\u003e              - ops@company.com\u003c/p\u003e\u003cp\u003e  - name: delete-old-snapshots\u003cbr/\u003e    resource: ebs-snapshot\u003cbr/\u003e    filters:\u003cbr/\u003e      - type: value\u003cbr/\u003e        key: \"tag:Age\"\u003cbr/\u003e        op: greater-than\u003cbr/\u003e        value: 90\u003cbr/\u003e      - not:\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:do-not-delete\"\u003cbr/\u003e            value: \"true\"\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: delete\u003c/p\u003e\u003cp\u003e  - name: stop-idle-instances\u003cbr/\u003e    resource: ec2\u003cbr/\u003e    filters:\u003cbr/\u003e      - type: metrics\u003cbr/\u003e        name: CPUUtilization\u003cbr/\u003e        days: 7\u003cbr/\u003e        value: 5\u003cbr/\u003e        op: less-than\u003cbr/\u003e      - not:\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:do-not-stop\"\u003cbr/\u003e            value: \"true\"\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: stop\u003c/p\u003e\u003cp\u003e  - name: release-unused-eips\u003cbr/\u003e    resource: network-addr\u003cbr/\u003e    filters:\u003cbr/\u003e      - type: value\u003cbr/\u003e        key: AssociationId\u003cbr/\u003e        value: null\u003cbr/\u003e      - not:\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:do-not-delete\"\u003cbr/\u003e            value: \"true\"\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: release\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Dry run\u003cbr/\u003ecustodian run cleanup.yml --dry-run\u003c/p\u003e\u003cp\u003e\u003ch1\u003eRun with output to S3 for logging\u003c/h1\u003e\u003cbr/\u003ecustodian run cleanup.yml \\\u003cbr/\u003e  --s3-bucket custodian-logs \\\u003cbr/\u003e  --region us-east-1\u003c/p\u003e\u003cp\u003e\u003ch1\u003eSchedule with Lambda\u003c/h1\u003e\u003cbr/\u003ecustodian run cleanup.yml \\\u003cbr/\u003e  --output-dir s3://custodian-logs/reports \\\u003cbr/\u003e  --region us-east-1 \\\u003cbr/\u003e  --lambda\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePros:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003ePolicy-driven, rules-based approach\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eSupports multiple clouds (AWS, Azure, GCP)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eRich filter and action ecosystem\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eCan be scheduled with Lambda\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eGood for ongoing governance\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCons:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eYAML configuration can be complex\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eSteeper learning curve than simple scripts\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eRequires more setup for basic cleanup\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eKomiser\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKomiser\u003c/strong\u003e is a cloud cost monitoring and resource governance tool. It's less about cleanup and more about visibility, but it can help identify waste.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eInstallation:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Docker\u003cbr/\u003edocker run -d -p 3000:3000 \\\u003cbr/\u003e  -v $HOME/.komiser:/app/.komiser \\\u003cbr/\u003e  komiser/komiser:latest\u003c/p\u003e\u003cp\u003e\u003ch1\u003eOr via Homebrew\u003c/h1\u003e\u003cbr/\u003ebrew tap komiserhq/komiser\u003cbr/\u003ebrew install komiser\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eConfiguration:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# komiser.yaml\u003cbr/\u003ecredentials:\u003cbr/\u003e  - name: aws-prod\u003cbr/\u003e    type: aws\u003cbr/\u003e    id: AKIA...\u003cbr/\u003e    secret: ...\u003cbr/\u003e    source: account\u003cbr/\u003e    account: 123456789012\u003c/p\u003e\u003cp\u003e  - name: gcp-prod\u003cbr/\u003e    type: gcp\u003cbr/\u003e    source: account\u003cbr/\u003e    credentials: /path/to/service-account.json\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eUsage:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Start dashboard\u003cbr/\u003ekomiser start\u003c/p\u003e\u003cp\u003e\u003ch1\u003eList all resources\u003c/h1\u003e\u003cbr/\u003ekomiser resources --provider aws\u003c/p\u003e\u003cp\u003e\u003ch1\u003eGet cost by service\u003c/h1\u003e\u003cbr/\u003ekomiser costs --provider aws --by service\u003c/p\u003e\u003cp\u003e\u003ch1\u003eGet cost by region\u003c/h1\u003e\u003cbr/\u003ekomiser costs --provider aws --by region\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKomiser Web Dashboard:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eView all resources across clouds\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eFilter by provider, region, service\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTrack costs in real-time\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIdentify underutilized resources\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003ePros:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eMulti-cloud support\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eBeautiful web dashboard\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eGood for visibility first, cleanup later\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eReal-time cost tracking\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eCons:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eLess automated cleanup than Cloud Custodian\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMore of a monitoring tool than a cleanup tool\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eRequires manual action on findings\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eAutomated cleanup without safety is dangerous. Here's how to protect production resources.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eTagging Strategy\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eRequired Tags:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Environment tag\u003cbr/\u003eEnvironment: production|staging|development\u003c/p\u003e\u003cp\u003e\u003ch1\u003eOwner tag\u003c/h1\u003e\u003cbr/\u003eOwner: team-name or individual-email\u003c/p\u003e\u003cp\u003e\u003ch1\u003ePurpose tag\u003c/h1\u003e\u003cbr/\u003ePurpose: what-the-resource-does\u003c/p\u003e\u003cp\u003e\u003ch1\u003eExemption tags\u003c/h1\u003e\u003cbr/\u003edo-not-delete: \"true\"\u003cbr/\u003edo-not-stop: \"true\"\u003cbr/\u003ekeep: \"true\"\u003cbr/\u003epreserve: \"true\"\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eTag Enforcement:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Cloud Custodian policy to enforce tagging\u003cbr/\u003epolicies:\u003cbr/\u003e  - name: enforce-resource-tagging\u003cbr/\u003e    resource: ec2\u003cbr/\u003e    filters:\u003cbr/\u003e      - or:\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:Environment\"\u003cbr/\u003e            value: absent\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:Owner\"\u003cbr/\u003e            value: absent\u003cbr/\u003e          - type: value\u003cbr/\u003e            key: \"tag:Purpose\"\u003cbr/\u003e            value: absent\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: notify\u003cbr/\u003e        subject: \"Untagged EC2 instance detected\"\u003cbr/\u003e        to:\u003cbr/\u003e          - ops@company.com\u003cbr/\u003e      - type: mark-for-op\u003cbr/\u003e        op: stop\u003cbr/\u003e        days: 7\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eDry-Run Mode\u003c/h3\u003e\u003c/p\u003e\u003cp\u003eAlways implement dry-run mode in your scripts:\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Pattern for dry-run\u003cbr/\u003edef delete_resource(resource_id, dry_run=True):\u003cbr/\u003e    \"\"\"Delete a resource with dry-run mode.\"\"\"\u003cbr/\u003e    if dry_run:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e        return False\u003cbr/\u003e    else:\u003cbr/\u003e        # Actual deletion\u003cbr/\u003e        try:\u003cbr/\u003e            client.delete(ResourceId=resource_id)\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            return True\u003cbr/\u003e        except Exception as e:\u003cbr/\u003e            print(\"\"\u003cbr/\u003e            return False\u003c/p\u003e\u003cp\u003e\u003ch1\u003eRequire explicit confirmation\u003c/h1\u003e\u003cbr/\u003eif not dry_run:\u003cbr/\u003e    confirm = input(\"This will delete resources. Type 'yes' to confirm: \")\u003cbr/\u003e    if confirm.lower() != 'yes':\u003cbr/\u003e        sys.exit(0)\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eApproval Workflows\u003c/h3\u003e\u003c/p\u003e\u003cp\u003eFor production environments, use approval workflows:\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Cloud Custodian with approval\u003cbr/\u003epolicies:\u003cbr/\u003e  - name: delete-unattached-volumes-with-approval\u003cbr/\u003e    resource: ebs\u003cbr/\u003e    filters:\u003cbr/\u003e      - type: value\u003cbr/\u003e        key: State\u003cbr/\u003e        value: available\u003cbr/\u003e    actions:\u003cbr/\u003e      - type: notify\u003cbr/\u003e        subject: \"Unattached EBS volumes found - Approve deletion?\"\u003cbr/\u003e        template: approval-email.j2\u003cbr/\u003e        to:\u003cbr/\u003e          - ops@company.com\u003cbr/\u003e        transport:\u003cbr/\u003e          type: sns\u003cbr/\u003e          topic: arn:aws:sns:us-east-1:123456789012:cleanup-approvals\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003eWhen recipients reply with \"APPROVE\", a Lambda function triggers the actual deletion.\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eMeasure your savings to prove ROI.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eBefore Cleanup\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Get current monthly cost estimate\u003cbr/\u003eaws ce get-cost-and-usage \\\u003cbr/\u003e  --time-period Start=$(date -u -d '30 days ago' --iso-8601=seconds),End=$(date -u --iso-8601=seconds) \\\u003cbr/\u003e  --granularity MONTHLY \\\u003cbr/\u003e  --metrics UnblendedCost \\\u003cbr/\u003e  --query 'ResultsByTime[0].Total.UnblendedCost' \\\u003cbr/\u003e  --output text\u003c/p\u003e\u003cp\u003e\u003ch1\u003eGet cost by service\u003c/h1\u003e\u003cbr/\u003eaws ce get-cost-and-usage \\\u003cbr/\u003e  --time-period Start=$(date -u -d '30 days ago' --iso-8601=seconds),End=$(date -u --iso-8601=seconds) \\\u003cbr/\u003e  --granularity MONTHLY \\\u003cbr/\u003e  --metrics UnblendedCost \\\u003cbr/\u003e  --group-by Type=DIMENSION,Key=SERVICE\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eAfter Cleanup\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e# Wait 30 days for data to settle\u003cbr/\u003e\u003ch1\u003eThen run same queries\u003c/h1\u003e\u003c/p\u003e\u003cp\u003e\u003ch1\u003eCalculate savings\u003c/h1\u003e\u003cbr/\u003eBEFORE_COST=$(echo \"$cost_before\")\u003cbr/\u003eAFTER_COST=$(echo \"$cost_after\")\u003cbr/\u003eSAVINGS=$(echo \"$BEFORE_COST - $AFTER_COST\" | bc)\u003cbr/\u003ePERCENT=$(echo \"$SAVINGS / $BEFORE_COST * 100\" | bc -l)\u003c/p\u003e\u003cp\u003eecho \"Before: $\\${BEFORE_COST}/month\"\u003cbr/\u003eecho \"After: $\\${AFTER_COST}/month\"\u003cbr/\u003eecho \"Savings: $\\${SAVINGS}/month (${PERCENT:.1f}%)\"\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eTracking Script\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cpre\u003e\u003ccode\u003e#!/usr/bin/env python3\u003cbr/\u003e\"\"\"\u003cbr/\u003eTrack cost savings from cleanup efforts.\u003cbr/\u003e\"\"\"\u003c/p\u003e\u003cp\u003eimport boto3\u003cbr/\u003efrom datetime import datetime, timedelta\u003cbr/\u003eimport json\u003c/p\u003e\u003cp\u003edef get_monthly_cost(days=30):\u003cbr/\u003e    \"\"\"Get monthly cost for the last N days.\"\"\"\u003cbr/\u003e    ce = boto3.client('ce')\u003cbr/\u003e    \u003cbr/\u003e    end_date = datetime.now().strftime('%Y-%m-%d')\u003cbr/\u003e    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\u003cbr/\u003e    \u003cbr/\u003e    response = ce.get_cost_and_usage(\u003cbr/\u003e        TimePeriod={\u003cbr/\u003e            'Start': start_date,\u003cbr/\u003e            'End': end_date\u003cbr/\u003e        },\u003cbr/\u003e        Granularity='MONTHLY',\u003cbr/\u003e        Metrics=['UnblendedCost']\u003cbr/\u003e    )\u003cbr/\u003e    \u003cbr/\u003e    return float(response['ResultsByTime'][0]['Total']['UnblendedCost']['Amount'])\u003c/p\u003e\u003cp\u003edef track_cleanup_results():\u003cbr/\u003e    \"\"\"Track and log cleanup results.\"\"\"\u003cbr/\u003e    \u003cbr/\u003e    # Load previous costs\u003cbr/\u003e    try:\u003cbr/\u003e        with open('cleanup_cost_history.json', 'r') as f:\u003cbr/\u003e            history = json.load(f)\u003cbr/\u003e    except FileNotFoundError:\u003cbr/\u003e        history = {'entries': []}\u003cbr/\u003e    \u003cbr/\u003e    # Get current cost\u003cbr/\u003e    current_cost = get_monthly_cost(30)\u003cbr/\u003e    \u003cbr/\u003e    # Calculate savings\u003cbr/\u003e    if history['entries']:\u003cbr/\u003e        previous_cost = history['entries'][0]['cost']\u003cbr/\u003e        savings = previous_cost - current_cost\u003cbr/\u003e        savings_percent = (savings / previous_cost) * 100 if previous_cost \u003e 0 else 0\u003cbr/\u003e    else:\u003cbr/\u003e        savings = 0\u003cbr/\u003e        savings_percent = 0\u003cbr/\u003e    \u003cbr/\u003e    # Add entry\u003cbr/\u003e    entry = {\u003cbr/\u003e        'date': datetime.now().isoformat(),\u003cbr/\u003e        'cost': current_cost,\u003cbr/\u003e        'savings': savings,\u003cbr/\u003e        'savings_percent': savings_percent\u003cbr/\u003e    }\u003cbr/\u003e    history['entries'].insert(0, entry)\u003cbr/\u003e    \u003cbr/\u003e    # Keep last 12 entries\u003cbr/\u003e    history['entries'] = history['entries'][:12]\u003cbr/\u003e    \u003cbr/\u003e    # Save\u003cbr/\u003e    with open('cleanup_cost_history.json', 'w') as f:\u003cbr/\u003e        json.dump(history, f, indent=2)\u003cbr/\u003e    \u003cbr/\u003e    # Print summary\u003cbr/\u003e    print(\"\"\u003cbr/\u003e    if savings \u003e 0:\u003cbr/\u003e        print(\"\"\u003cbr/\u003e    \u003cbr/\u003e    return entry\u003c/p\u003e\u003cp\u003eif __name__ == '__main__':\u003cbr/\u003e    track_cleanup_results()\u003cbr/\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eHere are specific savings I've seen from implementing automated cleanup.\u003c/p\u003e\u003cp\u003e\u003ch3\u003eExample 1: Startup with 50 EC2 Instances\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBefore:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $8,500\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIssues: 12 idle instances, 30 unattached volumes\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIdentified: 38% waste\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAfter cleanup:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eStopped 12 idle instances: $2,400/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eDeleted 30 volumes: $600/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal savings: $3,000/month (35%)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eROI:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eSetup time: 16 hours\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eInfrastructure cost: $20/month (Lambda + EventBridge)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly savings: $3,000\u003c/li\u003e\u003cbr/\u003e\u003cli\u003ePayback: \u003c 1 week\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eExample 2: Enterprise with 200 EBS Volumes\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBefore:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $15,200\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIssues: 87 unattached volumes (3.2 TB)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIdentified: 21% waste\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAfter cleanup:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eDeleted 87 unattached volumes: $1,280/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eImplemented 90-day snapshot retention: $450/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal savings: $1,730/month (11.4%)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eROI:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eSetup time: 24 hours\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eInfrastructure cost: $30/month\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly savings: $1,730\u003c/li\u003e\u003cbr/\u003e\u003cli\u003ePayback: 1 week\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eExample 3: Dev Environment Auto-Shutdown\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBefore:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $4,800\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIssues: Dev runs 24/7, used 8 hours/day\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIdentified: 67% runtime waste\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAfter auto-shutdown:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eDev shuts down 7 PM - 7 AM: $3,200/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eWeekends off: $1,000/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal savings: $4,200/month (87.5%)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eROI:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eSetup time: 8 hours\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eInfrastructure cost: $15/month (Lambda + EventBridge)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly savings: $4,200\u003c/li\u003e\u003cbr/\u003e\u003cli\u003ePayback: \u003c 1 day\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003eExample 4: Snapshot Sprawl Cleanup\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eBefore:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eMonthly cost: $22,000\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIssues: 3,500 snapshots, only 150 referenced by AMIs\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eIdentified: 2.1% waste (but significant in absolute terms)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eAfter cleanup:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eDeleted 3,350 unreferenced snapshots: $637/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eImplemented 30-day retention: $843/month saved\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eTotal savings: $1,480/month (6.7%)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eROI:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eSetup time: 12 hours\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eInfrastructure cost: $25/month\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eMonthly savings: $1,480\u003c/li\u003e\u003cbr/\u003e\u003cli\u003ePayback: 3 days\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePhase 1: Quick Wins (Week 1)\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003e[ ] Enable Cost Explorer\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Run manual audit of all regions\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Delete unattached EBS volumes (dry run → confirm → delete)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Release unused Elastic IPs\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Clean old snapshots (\u003e180 days)\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExpected savings:\u003c/strong\u003e 10-20%\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePhase 2: Automation (Weeks 2-3)\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003e[ ] Implement tagging strategy\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Deploy EBS cleanup script with dry-run mode\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Deploy snapshot cleanup script\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Set up Slack notifications for review\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExpected savings:\u003c/strong\u003e Additional 5-10%\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePhase 3: Scheduling (Week 4)\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003e[ ] Package cleanup scripts as Lambda functions\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Create EventBridge rules for weekly execution\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Implement cost tracking dashboard\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Set up approval workflow for production\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExpected savings:\u003c/strong\u003e Ongoing, automatic\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePhase 4: Advanced (Month 2)\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003e[ ] Deploy Cloud Custodian for policy-driven cleanup\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Set up dev environment auto-shutdown\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Implement right-sizing recommendations\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e[ ] Create FinOps dashboard\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eExpected savings:\u003c/strong\u003e 20-30% total reduction\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePitfall 1: Deleting Production Resources\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Automated cleanup deletes production resources because they weren't tagged.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eImplement mandatory tagging\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eUse do-not-delete/do-not-stop exemption tags\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eAlways run dry-run first\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eRequire approval for production environments\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePitfall 2: Deleting Recently Created Resources\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Resources created for testing are deleted before they're deployed.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eAdd age-based filters (e.g., skip resources \u003c 7 days old)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eUse separate cleanup schedules for dev and prod\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eImplement staging environment\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePitfall 3: Not Checking Dependencies\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Deleting a volume or snapshot breaks an AMI or running instance.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eAlways check AMI references before deleting snapshots\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eVerify volumes aren't attached before deletion\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eUse Cloud Custodian's dependency checking\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePitfall 4: No Rollback Plan\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Something goes wrong and there's no way to recover.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eKeep backups of critical snapshots\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eDocument all cleanup actions\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eUse CloudTrail for audit logs\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eHave a rollback plan for critical resources\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch3\u003ePitfall 5: Not Communicating with Teams\u003c/h3\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eProblem:\u003c/strong\u003e Engineers are surprised when their resources disappear.\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eSolution:\u003c/strong\u003e\u003cbr/\u003e\u003cli\u003eSend notification emails before cleanup\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eUse Slack notifications\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eCreate a cleanup review process\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eDocument cleanup policies\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003ch2\u003e$2\u003c/h2\u003e\u003c/p\u003e\u003cp\u003eCloud waste is real, expensive, and cumulative. But it's also solvable.\u003c/p\u003e\u003cp\u003eThe average cloud account wastes 30-40% of its spend on resources that aren't being used. That's not a rounding error—it's millions of dollars annually for mid-sized organizations.\u003c/p\u003e\u003cp\u003eBy implementing automated cleanup, you can:\u003c/p\u003e\u003cp\u003e\u003cli\u003e\u003cstrong\u003eEliminate zombie resources\u003c/strong\u003e—Unattached volumes, old snapshots, idle instances\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eStop paying for what you don't use\u003c/strong\u003e—Dev environments that run 24/7 but are only used 8 hours/day\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eBuild continuous optimization\u003c/strong\u003e—Weekly cleanup that prevents waste from accumulating\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eProve ROI\u003c/strong\u003e—Real cost savings you can show to leadership\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eKey takeaways:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003e\u003cstrong\u003eStart with visibility\u003c/strong\u003e—Enable Cost Explorer and run a manual audit\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eImplement safety first\u003c/strong\u003e—Tagging strategy, dry-run mode, approval workflows\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eAutomate early\u003c/strong\u003e—Python scripts → Lambda → EventBridge\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eMeasure everything\u003c/strong\u003e—Track before/after costs to prove ROI\u003c/li\u003e\u003cbr/\u003e\u003cli\u003e\u003cstrong\u003eIterate continuously\u003c/strong\u003e—Cleanup is never \"done,\" it's a process\u003c/li\u003e\u003c/p\u003e\u003cp\u003e\u003cstrong\u003eYour next steps:\u003c/strong\u003e\u003c/p\u003e\u003cp\u003e\u003cli\u003eRun the manual audit scripts (today)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eImplement the EBS cleanup script (this week)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eDeploy Lambda automation (this month)\u003c/li\u003e\u003cbr/\u003e\u003cli\u003eBuild toward continuous optimization (ongoing)\u003c/li\u003e\u003c/p\u003e\u003cp\u003eStop paying for what you're not using. Your cloud bill will thank you.\u003c/p\u003e\u003cp\u003eBuilt by engineers, for engineers.\u003cbr/\u003e    "])</script><script>self.__next_f.push([1,"5:[[\"$\",\"$Le\",null,{}],[\"$\",\"article\",null,{\"style\":{\"padding\":\"10rem 2rem 6rem\",\"maxWidth\":\"900px\",\"margin\":\"0 auto\",\"position\":\"relative\",\"zIndex\":1,\"animation\":\"fadeInUp 0.9s ease-out 0.2s both\"},\"children\":[[\"$\",\"header\",null,{\"style\":{\"marginBottom\":\"4rem\"},\"children\":[[\"$\",\"h1\",null,{\"style\":{\"fontFamily\":\"var(--font-space-grotesk)\",\"fontSize\":\"clamp(2rem, 5vw, 3rem)\",\"fontWeight\":700,\"lineHeight\":1.2,\"marginBottom\":\"1.5rem\",\"color\":\"var(--text-primary)\"},\"children\":\"Automated Cloud Resource Cleanup: Stop Paying for What You're Not Using\"}],[\"$\",\"p\",null,{\"style\":{\"fontSize\":\"1.15rem\",\"color\":\"var(--text-secondary)\",\"marginBottom\":\"1.5rem\",\"lineHeight\":1.8},\"children\":\"The average cloud account has 30-40% waste. Learn how to find and eliminate zombie resources automatically with Python, Bash, and open source tools.\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"flex\",\"alignItems\":\"center\",\"gap\":\"1rem\",\"fontSize\":\"0.85rem\",\"color\":\"var(--text-muted)\",\"fontFamily\":\"var(--font-jetbrains-mono)\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"padding\":\"0.4rem 1rem\",\"background\":\"rgba(0, 212, 255, 0.1)\",\"color\":\"var(--accent-cyan)\",\"border\":\"1px solid rgba(0, 212, 255, 0.2)\",\"borderRadius\":\"20px\"},\"children\":[\"20 min\",\" read\"]}],[\"$\",\"span\",null,{\"style\":{\"padding\":\"0.4rem 1rem\",\"background\":\"rgba(168, 85, 247, 0.1)\",\"color\":\"var(--accent-purple)\",\"border\":\"1px solid rgba(168, 85, 247, 0.2)\",\"borderRadius\":\"20px\"},\"children\":\"Cloud Cost Optimization\"}]]}]]}],[\"$\",\"div\",null,{\"style\":{\"lineHeight\":1.8,\"color\":\"var(--text-primary)\",\"fontSize\":\"1.05rem\"},\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}],\"$L10\"]}],\"$L11\"]\n"])</script><script>self.__next_f.push([1,"10:[\"$\",\"div\",null,{\"style\":{\"marginTop\":\"5rem\",\"maxWidth\":\"600px\",\"marginLeft\":\"auto\",\"marginRight\":\"auto\",\"background\":\"var(--bg-card)\",\"border\":\"1px solid var(--border-subtle)\",\"borderRadius\":\"24px\",\"padding\":\"3.5rem\",\"position\":\"relative\",\"overflow\":\"hidden\",\"boxShadow\":\"var(--card-shadow)\"},\"children\":[[\"$\",\"div\",null,{\"style\":{\"position\":\"absolute\",\"top\":\"-2px\",\"left\":\"-2px\",\"right\":\"-2px\",\"bottom\":\"-2px\",\"background\":\"linear-gradient(135deg, var(--accent-cyan), var(--accent-purple), var(--accent-cyan))\",\"borderRadius\":\"26px\",\"zIndex\":-1,\"opacity\":0.3}}],[\"$\",\"h2\",null,{\"style\":{\"fontFamily\":\"var(--font-space-grotesk)\",\"fontSize\":\"2rem\",\"fontWeight\":700,\"marginBottom\":\"0.75rem\",\"color\":\"var(--text-primary)\",\"position\":\"relative\",\"zIndex\":1},\"children\":\"Get weekly cloud cost tips\"}],[\"$\",\"p\",null,{\"style\":{\"color\":\"var(--text-secondary)\",\"marginBottom\":\"2rem\",\"fontSize\":\"1rem\",\"lineHeight\":1.8,\"position\":\"relative\",\"zIndex\":1},\"children\":\"Join engineers saving money on cloud costs. Actionable strategies every Friday.\"}],[\"$\",\"a\",null,{\"href\":\"https://sendfox.com/form/3qdz96/36enr2\",\"style\":{\"display\":\"inline-block\",\"fontFamily\":\"var(--font-nunito)\",\"fontSize\":\"1rem\",\"fontWeight\":700,\"padding\":\"1.2rem 2rem\",\"background\":\"linear-gradient(135deg, var(--accent-cyan) 0%, var(--accent-purple) 100%)\",\"color\":\"white\",\"border\":\"none\",\"borderRadius\":\"12px\",\"cursor\":\"pointer\",\"textDecoration\":\"none\",\"transition\":\"all 0.3s ease\",\"position\":\"relative\",\"zIndex\":1},\"children\":\"Subscribe (free)\"}]]}]\n"])</script><script>self.__next_f.push([1,"11:[\"$\",\"footer\",null,{\"style\":{\"padding\":\"3rem 2rem\",\"textAlign\":\"center\",\"borderTop\":\"1px solid var(--border-subtle)\",\"position\":\"relative\",\"zIndex\":1,\"animation\":\"fadeInUp 0.9s ease-out 0.4s both\"},\"children\":[\"$\",\"p\",null,{\"style\":{\"fontFamily\":\"var(--font-nunito)\",\"fontSize\":\"0.85rem\",\"color\":\"var(--text-muted)\"},\"children\":\"© 2026 Cost Nimbus. Built by engineers, for engineers.\"}]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"12:I[64481,[\"/_next/static/chunks/d6bee75b35a28280.js\",\"/_next/static/chunks/8189c34e001333f7.js\"],\"IconMark\"]\n8:null\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"title\",\"0\",{\"children\":\"Automated Cloud Resource Cleanup: Stop Paying for What You're Not Using | Cost Nimbus | Cost Nimbus\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"The average cloud account has 30-40% waste. Learn how to find and eliminate zombie resources automatically with Python, Bash, and open source tools.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"keywords\",\"content\":\"Cloud Cost Optimization, cloud costs, AWS optimization, FinOps, cloud savings, cost management\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Cost Nimbus - Cloud Cost Intelligence\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"Real cloud cost optimization strategies built by engineers, for engineers. Save thousands monthly with battle-tested techniques.\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Cost Nimbus\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Cost Nimbus - Cloud Cost Intelligence\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Real cloud cost optimization strategies built by engineers, for engineers. Save thousands monthly with battle-tested techniques.\"}],[\"$\",\"link\",\"10\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L12\",\"11\",{}]]\n"])</script></body></html>